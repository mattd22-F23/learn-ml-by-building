{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8588713c",
   "metadata": {
    "id": "8588713c"
   },
   "source": [
    "# Neural Archaeology: Decoding and Rewiring the Hidden Mind of Language Models\n",
    "\n",
    "## ECE4424/CS4824: Machine Learning, Fall 2025\n",
    "**Instructor**: Prof. Ming Jin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba0a0a8",
   "metadata": {
    "id": "2ba0a0a8"
   },
   "source": [
    "### Submission Requirements\n",
    "\n",
    "1. **Complete ALL code implementations** marked with `# YOUR CODE HERE`\n",
    "2. **Complete ALL analysis sections** marked as \"Required Analysis\"\n",
    "3. **Run all cells** to show outputs (including visualizations)\n",
    "4. **Save outputs**: Ensure all plots are visible in the notebook\n",
    "5. **Submit  the PDF of the Notebook**: Print the Notebook with clear results in a PDF format.\n",
    "\n",
    "**Note**: Required Analysis sections are clearly marked throughout the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13c3ebf",
   "metadata": {
    "id": "b13c3ebf"
   },
   "source": [
    "## Project Overview: The Quest to Understand Machine Minds\n",
    "\n",
    "<img src=\"assets/brain-neural.png\" alt=\"Brain Neural Network\" width=\"300\" align=\"right\" style=\"margin-left: 20px; margin-bottom: 10px;\">\n",
    "\n",
    "Imagine having the ability to peer directly into a human brain, watching thoughts form in real-time, identifying the exact neurons that fire when someone feels joy versus fear, and even being able to gently nudge those neurons to change the person's emotional state. This level of understanding and control has long been a dream in neuroscience. Today, we're going to achieve something remarkably similar, but with artificial intelligence.\n",
    "\n",
    "\n",
    "Language models like GPT and LLaMA are often called \"black boxes\". We know what goes in and what comes out, but the middle remains mysterious. In this notebook, we'll embark on a journey of **neural archaeology**, excavating the hidden layers of these models to understand how they encode concepts like safety, emotion, and truthfulness.\n",
    "\n",
    "This notebook builds on several groundbreaking research directions: **representation engineering** from [Zou et al. (2023)](https://arxiv.org/abs/2310.01405), the **circuit breakers** methodology from [Zou et al., 2024](https://www.circuit-breaker.ai/), and refusal mechanisms inspired by [Zhang et al., 2024](https://arxiv.org/abs/2409.14586) and [Sel et al., 2025](https://arxiv.org/abs/2503.08919). We synthesize these techniques into a hands-on exploration where you'll build practical safety detectors and discover how emotions organize geometrically in activation space.\n",
    "\n",
    "By the end of this notebook, you'll have built a complete system that can:\n",
    "1. **Read the model's mind**: extracting and visualizing its internal thought patterns\n",
    "2. **Identify cognitive signatures**: finding the neural patterns for safety, emotions, and other concepts  \n",
    "3. **Build safety detectors**: creating classifiers to identify harmful content\n",
    "4. **Understand representation geometry**: exploring how concepts organize in neural space\n",
    "\n",
    "This hands-on exploration connects cutting-edge research to practical implementation, giving you both theoretical understanding and engineering skills in AI safety and interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba970cb",
   "metadata": {
    "id": "1ba970cb"
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "Through this notebook, you will:\n",
    "- **Implement PCA from scratch** to understand unsupervised dimensionality reduction\n",
    "- **Apply K-means clustering** to discover natural groupings in neural representations\n",
    "- **Compare supervised vs unsupervised learning** for representation discovery\n",
    "- **Analyze layer-wise information processing** in Transformer architectures\n",
    "- **Build and evaluate safety detection systems** using neural representations\n",
    "- **Test adversarial robustness** of safety detection systems\n",
    "- **Think critically about AI safety and ethics** through hands-on experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb06d2d",
   "metadata": {
    "id": "0eb06d2d"
   },
   "source": [
    "## Setup Environment\n",
    "\n",
    "### Quick Start Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0209ce3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0209ce3",
    "outputId": "6406b2cb-56c1-4e63-cb9e-d9c7d980d134"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CORE IMPORTS\n",
    "# ============================================================\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "\n",
    "# Transformers and model utilities\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Scientific computing\n",
    "from sklearn.decomposition import PCA as SklearnPCA\n",
    "from sklearn.metrics import silhouette_score, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# ============================================================\n",
    "# ENVIRONMENT DETECTION AND CONFIGURATION\n",
    "# ============================================================\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "IS_MPS = torch.backends.mps.is_available()\n",
    "\n",
    "print(f\"Environment: {'Google Colab' if IS_COLAB else 'Local'}\")\n",
    "print(f\"MPS Available: {IS_MPS}\")\n",
    "\n",
    "# Device and parameter configuration\n",
    "if IS_COLAB and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    DTYPE = torch.float16\n",
    "    BATCH_SIZE = 16\n",
    "elif IS_MPS:\n",
    "    device = torch.device(\"mps\")\n",
    "    DTYPE = torch.float32  # MPS doesn't handle float16 well\n",
    "    BATCH_SIZE = 8\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DTYPE = torch.float32\n",
    "    BATCH_SIZE = 4\n",
    "\n",
    "print(f\"Neural Laboratory initialized on {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Data type: {DTYPE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# ============================================================\n",
    "# REPRODUCIBILITY AND UTILITIES\n",
    "# ============================================================\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU/CPU memory caches to prevent OOM during long operations\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    elif IS_MPS:\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "def get_layer_ranges(model, print_config=True):\n",
    "    \"\"\"\n",
    "    Get layer ranges for early, middle, and late layers based on model architecture.\n",
    "\n",
    "    This function dynamically calculates appropriate layer indices based on the\n",
    "    total number of layers in the model, making the code compatible with different\n",
    "    architectures (e.g., SmolLM with 24 layers).\n",
    "\n",
    "    Args:\n",
    "        model: The transformer model\n",
    "        print_config: Whether to print the layer configuration (default: True)\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing:\n",
    "            - 'total': Total number of layers\n",
    "            - 'early': List of early layer indices (first ~25%)\n",
    "            - 'middle': List of middle layer indices (middle ~50%)\n",
    "            - 'late': List of late layer indices (last ~25%)\n",
    "            - 'exploration': Sampled layers for exploration (8-10 layers)\n",
    "            - 'safety_layers': Layers for safety detection (last 4 layers)\n",
    "            - 'last_layer': Last layer index\n",
    "    \"\"\"\n",
    "    n_layers = model.config.num_hidden_layers\n",
    "\n",
    "    # Define ranges as proportions\n",
    "    early_end = n_layers // 4\n",
    "    middle_start = n_layers // 4\n",
    "    middle_end = 3 * n_layers // 4\n",
    "    late_start = 3 * n_layers // 4\n",
    "\n",
    "    # Create explicit layer lists\n",
    "    early_layers = list(range(0, early_end))\n",
    "    middle_layers = list(range(middle_start, middle_end))\n",
    "    late_layers = list(range(late_start, n_layers))\n",
    "\n",
    "    # Sample layers for exploration (evenly spaced)\n",
    "    exploration_layers = [0]  # Always include first layer\n",
    "    step = max(1, n_layers // 8)\n",
    "    exploration_layers.extend(list(range(step, n_layers, step)))\n",
    "    if exploration_layers[-1] != n_layers - 1:\n",
    "        exploration_layers.append(n_layers - 1)  # Always include last layer\n",
    "\n",
    "    # Safety-critical layers (last 4 layers where abstract concepts emerge)\n",
    "    safety_layers = list(range(max(0, n_layers - 4), n_layers))\n",
    "\n",
    "    config = {\n",
    "        'total': n_layers,\n",
    "        'early': early_layers,\n",
    "        'middle': middle_layers,\n",
    "        'late': late_layers,\n",
    "        'exploration': exploration_layers,\n",
    "        'safety_layers': safety_layers,\n",
    "        'last_layer': n_layers - 1\n",
    "    }\n",
    "\n",
    "    # Print configuration if requested\n",
    "    if print_config:\n",
    "        # Extract model name from config\n",
    "        model_name = model.config._name_or_path.split('/')[-1] if hasattr(model.config, '_name_or_path') else 'model'\n",
    "\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Layer Configuration for {model_name} ({n_layers} layers)\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Early layers\n",
    "        early_range = f\"0-{early_end-1}\" if early_layers else \"none\"\n",
    "        early_preview = str(early_layers[:5]) + \"...\" if len(early_layers) > 5 else str(early_layers)\n",
    "        print(f\"Early layers ({early_range}):   {early_preview}\")\n",
    "\n",
    "        # Middle layers\n",
    "        if middle_layers:\n",
    "            middle_range = f\"{middle_layers[0]}-{middle_layers[-1]}\"\n",
    "            middle_preview = str(middle_layers[:5]) + \"...\" if len(middle_layers) > 5 else str(middle_layers)\n",
    "            print(f\"Middle layers ({middle_range}): {middle_preview}\")\n",
    "\n",
    "        # Late layers\n",
    "        late_range = f\"{late_layers[0]}-{late_layers[-1]}\" if late_layers else \"none\"\n",
    "        print(f\"Late layers ({late_range}):   {late_layers}\")\n",
    "\n",
    "        # Other info\n",
    "        print(f\"Exploration sample:    {exploration_layers}\")\n",
    "        print(f\"Safety layers:         {safety_layers}\")\n",
    "        print(f\"Last layer:            {config['last_layer']}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "    return config\n",
    "\n",
    "# ============================================================\n",
    "# DATA AND ENVIRONMENT SETUP\n",
    "# ============================================================\n",
    "if IS_COLAB:\n",
    "    # Colab setup\n",
    "    !pip install torch transformers datasets scikit-learn matplotlib seaborn tqdm -q\n",
    "    !pip install accelerate sentencepiece -q\n",
    "    !git clone https://github.com/jinming99/learn-ml-by-building.git\n",
    "    DATA_PATH = \"/content/learn-ml-by-building/Project 2 Neural Archaeology/data\"\n",
    "    sys.path.append('/content/learn-ml-by-building/Project 2 Neural Archaeology')\n",
    "else:\n",
    "    # Local setup\n",
    "    DATA_PATH = \"./data\"\n",
    "\n",
    "    # Download data if it doesn't exist\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        print(\"Downloading data...\")\n",
    "        subprocess.run([\"git\", \"clone\", \"https://github.com/jinming99/learn-ml-by-building.git\", \"temp_repo\"])\n",
    "        subprocess.run([\"cp\", \"-r\", \"temp_repo/Project 2 Neural Archaeology/data\", DATA_PATH])\n",
    "        subprocess.run([\"rm\", \"-rf\", \"temp_repo\"])\n",
    "        print(\"Data downloaded!\")\n",
    "\n",
    "# Create result directories\n",
    "dirs_to_create = [\n",
    "    'models',\n",
    "    'results/visualizations',\n",
    "    'results/evaluations',\n",
    "    'results/saved_states',\n",
    "    'results/student_analysis'\n",
    "]\n",
    "\n",
    "for dir_path in dirs_to_create:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69bc4f6",
   "metadata": {
    "id": "a69bc4f6"
   },
   "source": [
    "## Section 0: Foundation - Building Our Neural Laboratory\n",
    "\n",
    "In neuroscience, before we can study the brain, we need proper instruments: EEG machines, fMRI scanners, and precise measurement tools. Similarly, we'll build our toolkit for exploring language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67dba67",
   "metadata": {
    "id": "d67dba67"
   },
   "source": [
    "### Loading the Circuit Breaker Dataset: Our Moral Training Data\n",
    "\n",
    "The [circuit breaker dataset](https://github.com/GraySwanAI/circuit-breakers) contains examples of safe and unsafe model behaviors. We'll use this to teach our model to recognize and avoid harmful outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6c4aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1e6c4aa",
    "outputId": "950f1c2e-77c5-4461-eab4-847c980568a3"
   },
   "outputs": [],
   "source": [
    "def load_circuit_breaker_data(base_path=DATA_PATH):\n",
    "    \"\"\"\n",
    "    Load circuit breaker training and validation data.\n",
    "\n",
    "    This dataset contains the moral knowledge we'll implant into our model:\n",
    "    - Prompts: Potentially unsafe user requests\n",
    "    - Unsafe outputs: What the model shouldn't say\n",
    "    - Safe outputs: Appropriate refusals\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    # Load from safety subdirectory\n",
    "    safety_path = os.path.join(base_path, 'safety')\n",
    "\n",
    "    # Load training data\n",
    "    train_path = os.path.join(safety_path, 'circuit_breakers_train.json')\n",
    "    if not os.path.exists(train_path):\n",
    "        raise FileNotFoundError(f\"Required file not found: {train_path}\")\n",
    "\n",
    "    with open(train_path, 'r') as f:\n",
    "        train_data = json.load(f)\n",
    "\n",
    "    # Load validation data\n",
    "    val_path = os.path.join(safety_path, 'circuit_breakers_val.json')\n",
    "    if not os.path.exists(val_path):\n",
    "        raise FileNotFoundError(f\"Required file not found: {val_path}\")\n",
    "\n",
    "    with open(val_path, 'r') as f:\n",
    "        val_data = json.load(f)\n",
    "\n",
    "    # Extract components\n",
    "    data['train'] = {\n",
    "        'prompts': [item['prompt'] for item in train_data],\n",
    "        'unsafe_outputs': [item['output'] for item in train_data],\n",
    "        'safe_outputs': [item['llama3_output'] for item in train_data],\n",
    "        'categories': [item.get('category', 'unknown') for item in train_data]\n",
    "    }\n",
    "\n",
    "    data['val'] = {\n",
    "        'prompts': [item['prompt'] for item in val_data],\n",
    "        'unsafe_outputs': [item['output'] for item in val_data],\n",
    "        'safe_outputs': [item['llama3_output'] for item in val_data],\n",
    "        'categories': [item.get('category', 'unknown') for item in val_data]\n",
    "    }\n",
    "\n",
    "    print(f\"Loaded {len(data['train']['prompts'])} training examples\")\n",
    "    print(f\"Loaded {len(data['val']['prompts'])} validation examples\")\n",
    "\n",
    "    # Show category distribution\n",
    "    categories = set(data['train']['categories'])\n",
    "    print(f\"Categories: {list(categories)[:5]}{'...' if len(categories) > 5 else ''}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# Load the moral training data\n",
    "cb_data = load_circuit_breaker_data()\n",
    "\n",
    "# Examine a sample\n",
    "print(\"\\nSample Circuit Breaker Training Example:\")\n",
    "print(\"=\"*60)\n",
    "idx = 0\n",
    "print(f\"User Prompt: {cb_data['train']['prompts'][idx]}\")\n",
    "print(f\"Unsafe Response: {cb_data['train']['unsafe_outputs'][idx][:200]}...\")\n",
    "print(f\"Safe Response: {cb_data['train']['safe_outputs'][idx][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1fe74e",
   "metadata": {
    "id": "5a1fe74e"
   },
   "source": [
    "### Loading Emotion Data: The Affective Palette\n",
    "\n",
    "The emotion dataset contains scenarios that evoke different emotional responses. We'll use this to understand how the model represents emotions internally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432c2556",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "432c2556",
    "outputId": "e2db0b6b-6ab6-4862-b263-5d167097bf9f"
   },
   "outputs": [],
   "source": [
    "def load_emotion_data(base_path=DATA_PATH):\n",
    "    \"\"\"\n",
    "    Load emotion datasets - the building blocks of affective computing.\n",
    "\n",
    "    Each emotion category contains scenarios that evoke that emotion.\n",
    "    We'll use these to map the model's emotional landscape.\n",
    "    \"\"\"\n",
    "    emotions = {}\n",
    "\n",
    "    emotions_path = os.path.join(base_path, 'emotions')\n",
    "    if not os.path.exists(emotions_path):\n",
    "        raise FileNotFoundError(f\"Emotions directory not found: {emotions_path}\")\n",
    "\n",
    "    emotion_files = [f for f in os.listdir(emotions_path) if f.endswith('.json')]\n",
    "\n",
    "    if not emotion_files:\n",
    "        raise FileNotFoundError(f\"No emotion JSON files found in {emotions_path}\")\n",
    "\n",
    "    for filename in emotion_files:\n",
    "        emotion_name = filename.replace('.json', '')\n",
    "        filepath = os.path.join(emotions_path, filename)\n",
    "\n",
    "        with open(filepath, 'r') as f:\n",
    "            scenarios = json.load(f)\n",
    "            emotions[emotion_name] = scenarios\n",
    "\n",
    "    print(f\"Loaded {len(emotions)} emotion categories:\")\n",
    "    for emotion, scenarios in emotions.items():\n",
    "        print(f\"  {emotion}: {len(scenarios)} scenarios\")\n",
    "\n",
    "    return emotions\n",
    "\n",
    "# Load emotional training data\n",
    "emotion_data = load_emotion_data()\n",
    "\n",
    "# Sample the emotional palette\n",
    "print(\"\\nEmotional Palette Samples:\")\n",
    "print(\"=\"*60)\n",
    "for emotion in list(emotion_data.keys()):\n",
    "    print(f\"\\n{emotion.upper()}:\")\n",
    "    for scenario in emotion_data[emotion][:2]:\n",
    "        print(f\"  - {scenario}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a917530",
   "metadata": {
    "id": "6a917530"
   },
   "source": [
    "### Model Architecture: SmolLM-1.7B-Instruct\n",
    "\n",
    "We'll work with **SmolLM-1.7B-Instruct**, a compact yet capable language model for our neural archaeology exploration:\n",
    "\n",
    "- **Architecture**: 24 layers, 1.7B parameters\n",
    "- **Usage**: Exploration and concept learning, understanding representation structure, training safety detectors\n",
    "- **Rationale**: Fast iteration for learning, lower memory requirements, same architectural principles as larger models\n",
    "\n",
    "This model is powerful enough to exhibit complex behaviors while remaining efficient to run on standard hardware.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VMn0A5msU6mZ",
   "metadata": {
    "id": "VMn0A5msU6mZ"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace \"YOUR_HF_TOKEN\" with the actual token you copied\n",
    "login(token=\"YOUR_HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54a2123",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565,
     "referenced_widgets": [
      "5cf6e14604ee4cbb90ea7f374c127208",
      "ec757bf395c4436a9469a5c79bf61d23",
      "cc72be3c90024888979e194f7d22f1bc",
      "bae897e743a24edd9c6e8159f6961977",
      "656cc4584d9e49699fa3fdd6c7767969",
      "a094c5b4e6474257b2d4be833d9069d2",
      "81f76d9e08c140bda6a050335ad89971",
      "1880536b5117470787e281a93311c6e6",
      "644c316bde7d478e9dae9e49f73cb829",
      "4aeb57348db34ba19d4a1510f248508c",
      "c54118528ac04c05a0af635afc157de5",
      "3e20ec616ad54ac3957572b60a6dec01",
      "e72423f831fd46f3bf06c0ab7ba76797",
      "9921643026b34e85a5147184605e45d3",
      "65446d8272194d7e99923ec420d03306",
      "6aa26741142141a29bf183e176a6620d",
      "3c2fdce86da6435ca363e66e46db660c",
      "db67461ca6034592856480e02b479252",
      "a6d461c946954f6ea569f5619325fdbd",
      "baa371ceb638480bbd1c25319c7cc5d9",
      "ed3eb6b6939645e4b30c661dacf00f2b",
      "ef92d284cce1430e81ccf3e322c2cab3",
      "0f6224b6d99c41eabcec948735274052",
      "8d6586b7682e4c1da166373c2c638a74",
      "3e6eb46ac8ce4afb889826c30221f9a6",
      "79b49afd52214e8abacfd77499b6370b",
      "c747b1e0398840d2aec8bc86432c9c69",
      "636341bfc52d43f985f69e35f86f3190",
      "ed54017801bf43a48bf857706cbcf5d4",
      "ea2bb067b26d40f29e56209e2315a3ba",
      "8d114858bbf649a58c3bf48ee72f91b5",
      "d49643472146465a9db63534352ff2c6",
      "f959e07b8837418e8f49adc4fa17ccf2",
      "ab985892d83d4bcabfb1b15dc6752b40",
      "d6bee1d9697041d7a88c084da11850e4",
      "41867e86de9a4fc2bf8388ee9f09c484",
      "6bf4f9d3822a45d696fb69f80420858a",
      "0e998ae00b574c08bb95ee4ca54b7b18",
      "b03f265cdd7845e3a93b5515fd9b0498",
      "713d2df2162a41ed96e92304a4678606",
      "c12c9f985b0a49078dd9fc3a6cde1a88",
      "14f85c8d3a15411283b21a30ce52eee1",
      "9a5c2e4a36c842c89a70d56e0dfbc209",
      "561cff1e257a42ff86052de8e9111bda",
      "538f9d622be747f09aa6da58a2732acc",
      "18eb41620ac94e6b86e14e39738a3eda",
      "8d7f5b86b4e04942a9f6e47624c4ba49",
      "aec17c3c77e648d29ea527fbe67a4a8a",
      "7527ac40d7bd436381a82c844beaf717",
      "d814a1478330460683f79de97cd35fb2",
      "f94c6e535de64358bf281a7c93577c4a",
      "69867e7d2b6b46bbadbb2147c48cfcab",
      "5490c1d7addd421588888c6d6353b970",
      "de050f3c08b84177aae0ca8419dc40a1",
      "992980546f8a4c2180167bc08246bbc0",
      "0af57d40c6cd46dd8d093bb5212d00cf",
      "5fcdc762c0444c7da401927838d2ea78",
      "e8f6b75cbd1e49d2a0ef18e0fa40933a",
      "c0950e254a824dab863ce525720a433a",
      "fd4bf01df914490b84b7a2fa7389d4f4",
      "9f3e62985b594194bf984c74f451d3c7",
      "9e27b9466d3e4030bb85d955b6ea8f96",
      "70492af00c0e4df183c2b473d7b276c1",
      "8a9e3028ac794088959e473fd5fcf402",
      "e790a2638af54662a602aa3faa836f2d",
      "fff0ccbbd7874f2e8651303f7c53f602",
      "1b9b3055b20240c49adac22157dd0d13",
      "70babe96b7b1429fa17f4c40cad9c152",
      "1be4463d2cd84c64b98c61f30f7862e4",
      "81dcf013dedc4f0ba7b32dd117ebae40",
      "58aa31d9da994c15975f460d1e408f0d",
      "5863477165f14251976615a199a8e351",
      "882ce2a9bf3c4d3b88c8e7c746b7c097",
      "14888ecd16404cc7b3a27f5ba19d5c77",
      "f0d5f4aaffbf4c3481be47f8c5a6ee41",
      "e84762ae5fa44d1686680aa6d91ea723",
      "6b1635ab51884e188b524377a4825a0e",
      "aa4b75d65c224b10a27abab3a9fdc73b",
      "46ed85e98bb54834bce1cb957f1bf386",
      "1d85581233bf41cf9d1800344e79e38c",
      "2ec0ec2709974a4e8b9f39255d5617e7",
      "d85154d0cf464328a1eb72326e4f97d5",
      "4926d614003c489dbe0553ae0763871b",
      "308364e795c843e2abd0f219279e0bbd",
      "b944feb9040343cea1095a8de5a2812f",
      "4a9c6537f0e54506a704dd583a9c97a4",
      "dea9624623804c18bce55ca0fdd723de",
      "77ec276a0577468094eccb16f0dde63d"
     ]
    },
    "id": "a54a2123",
    "outputId": "c4782789-ebc1-4ba5-b639-60e9532dd966"
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_name=\"HuggingFaceTB/SmolLM-1.7B-Instruct\"):\n",
    "    \"\"\"\n",
    "    Load a language model for experimentation.\n",
    "\n",
    "    Supports: SmolLM-1.7B-Instruct and other HuggingFace models.\n",
    "    \"\"\"\n",
    "    print(f\"Preparing model {model_name} for experimentation...\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Use environment-specific settings\n",
    "    if IS_COLAB:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=DTYPE,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "    else:\n",
    "        # For local, don't use device_map=\"auto\" as it may not work well with MPS\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=DTYPE\n",
    "        )\n",
    "        model = model.to(device)  # Explicitly move to device\n",
    "\n",
    "    # Ensure padding token\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Standard transformer architecture - access pattern: model.model.layers[i]\n",
    "    layer_attr = \"model.layers\"\n",
    "\n",
    "    print(f\"Loaded {model_name}\")\n",
    "    print(f\"  Hidden dim: {model.config.hidden_size}, Layers: {model.config.num_hidden_layers}\")\n",
    "\n",
    "    return model, tokenizer, layer_attr\n",
    "\n",
    "model, tokenizer, layer_attr = load_model_and_tokenizer()\n",
    "\n",
    "# Initialize layer ranges for SmolLM\n",
    "LAYER_CONFIG = get_layer_ranges(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f3ad24",
   "metadata": {
    "id": "20f3ad24"
   },
   "source": [
    "### Test the Model\n",
    "\n",
    "Try different prompts to see how the model responds. The model uses chat templates for instruction following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279f33b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6279f33b",
    "lines_to_next_cell": 2,
    "outputId": "c5df2f4f-6f05-44a9-a6ee-81741188f8d2"
   },
   "outputs": [],
   "source": [
    "def test_model_generation(prompt, max_new_tokens=100):\n",
    "    \"\"\"\n",
    "    Test the model with a custom prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt: Your question or instruction\n",
    "        max_new_tokens: Maximum length of response\n",
    "    \"\"\"\n",
    "    print(f\"Model: SmolLM-1.7B-Instruct\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "\n",
    "    # Use chat template for instruct models\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    # Handle device placement properly\n",
    "    if IS_COLAB:\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    else:\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature=0.2, top_p=0.9, do_sample=True)\n",
    "\n",
    "    # Only decode the newly generated tokens, not the input prompt\n",
    "    input_length = inputs['input_ids'].shape[1]\n",
    "    response = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "    print(f\"Response: {response}\\n\")\n",
    "    return response\n",
    "\n",
    "# Test the model with a sample prompt\n",
    "print(\"Testing SmolLM:\")\n",
    "print(\"=\"*60)\n",
    "_ = test_model_generation(\"Hello! What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7e61aa",
   "metadata": {
    "id": "6f7e61aa"
   },
   "source": [
    "## Mini-Tutorial: Key Concepts for Neural Archaeology\n",
    "\n",
    "Before diving into the analysis, let's understand the key terms we'll be working with:\n",
    "\n",
    "#### **What are Tokens?**\n",
    "Think of tokens as the \"words\" a language model actually sees. Just like how you break a sentence into words, language models break text into **tokens**, which can be words, parts of words, or even single characters.\n",
    "\n",
    "**Example:** The sentence \"I think your code is overpythonized\" might be split into tokens like:\n",
    "- `[\"I\", \" think\", \" your\", \" code\", \" is\", \" over\", \"python\", \"ized\"]`\n",
    "\n",
    "*Learn more:* [OpenAI Tokenizer Tool](https://platform.openai.com/tokenizer) | [Article](https://quickchat.ai/post/tokens-entropy-question)\n",
    "\n",
    "#### **What are Hidden States and Layers?**\n",
    "Hidden states are the **internal thoughts** of the neural network at each layer. When the model processes a token, it creates a numerical representation (a vector) that captures what it \"knows\" about that token at that point in processing.\n",
    "\n",
    "A language model is organized into **layers** stacked on top of each other - like floors in a building. Each layer refines and transforms the representation from the previous layer. Typically:\n",
    "\n",
    "- **Early layers:** Capture basic patterns (spelling, grammar)\n",
    "- **Middle layers:** Capture meaning and relationships\n",
    "- **Late layers:** Capture abstract concepts and task-specific information\n",
    "\n",
    "*Visualization:* [Jay Alammar's Hidden States Guide](http://jalammar.github.io/hidden-states/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2c454",
   "metadata": {
    "id": "7be2c454"
   },
   "source": [
    "## Section 1: First Contact - Observing Natural Neural Patterns\n",
    "\n",
    "Before we can manipulate a system, we must understand it. Let's observe how information flows through the model's layers and how different concepts create distinct neural signatures.\n",
    "\n",
    "### Creating Diverse Test Data\n",
    "\n",
    "We'll create a diverse dataset that includes safety-related content, emotional scenarios, and neutral text to explore how the model represents different types of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ce614",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e27ce614",
    "lines_to_next_cell": 2,
    "outputId": "acc66a11-756b-4fd2-d27f-5e14bb61d537"
   },
   "outputs": [],
   "source": [
    "# Create a much larger and more diverse test set\n",
    "exploration_texts = []\n",
    "exploration_labels = []\n",
    "\n",
    "# Use circuit breaker data for clear safety contrast\n",
    "print(\"Loading safety samples from circuit breaker data...\")\n",
    "n_safety = min(50, len(cb_data['train']['prompts']))\n",
    "\n",
    "# Group UNSAFE together\n",
    "unsafe_texts = []\n",
    "for i in range(n_safety):\n",
    "    unsafe_text = cb_data['train']['prompts'][i] + \" \" + cb_data['train']['unsafe_outputs'][i][:100]\n",
    "    # Note: [:100] cutoff captures key semantic differences efficiently:\n",
    "    # >90% of safe/unsafe outputs contain refusal/harmful content in first 100 chars\n",
    "    unsafe_texts.append(unsafe_text)\n",
    "    exploration_texts.append(unsafe_text)\n",
    "    exploration_labels.append('unsafe')\n",
    "\n",
    "# Group SAFE together\n",
    "safe_texts = []\n",
    "for i in range(n_safety):\n",
    "    safe_text = cb_data['train']['prompts'][i] + \" \" + cb_data['train']['safe_outputs'][i][:100]\n",
    "    safe_texts.append(safe_text)\n",
    "    exploration_texts.append(safe_text)\n",
    "    exploration_labels.append('safe')\n",
    "\n",
    "# Emotional content - use more samples\n",
    "# Pick only contrasting emotions (high arousal negative vs positive)\n",
    "print(\"Loading emotion samples...\")\n",
    "emotions_to_use = ['joy','anger']\n",
    "# emotions_to_use = []\n",
    "for emotion in emotions_to_use:\n",
    "    if emotion in emotion_data:\n",
    "        # Use up to 15 samples per emotion\n",
    "        n_emotion_samples = min(30, len(emotion_data[emotion]))\n",
    "        for scenario in emotion_data[emotion][:n_emotion_samples]:\n",
    "            exploration_texts.append(scenario)\n",
    "            exploration_labels.append(f'emotion_{emotion}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Add more diverse neutral content\n",
    "print(\"Adding neutral samples...\")\n",
    "neutral_samples = [\n",
    "    \"The capital of France is Paris.\",\n",
    "    \"Water boils at 100 degrees Celsius.\",\n",
    "    \"There are seven days in a week.\",\n",
    "    \"Mathematics is the study of numbers and patterns.\",\n",
    "    \"The Earth orbits around the Sun.\",\n",
    "    \"Photosynthesis converts light into chemical energy.\",\n",
    "    \"The Pacific Ocean is the largest ocean.\",\n",
    "    \"Shakespeare wrote Romeo and Juliet.\",\n",
    "    \"The human body has 206 bones.\",\n",
    "    \"Gold is a chemical element with symbol Au.\",\n",
    "    \"Mount Everest is the highest mountain.\",\n",
    "    \"The speed of light is approximately 300,000 km/s.\",\n",
    "    \"DNA contains genetic instructions.\",\n",
    "    \"The Great Wall of China is visible from space is a myth.\",\n",
    "    \"Chess is a strategic board game.\",\n",
    "    \"Python is a programming language.\",\n",
    "    \"The Amazon rainforest produces oxygen.\",\n",
    "    \"Gravity causes objects to fall.\",\n",
    "    \"The moon affects ocean tides.\",\n",
    "    \"Atoms are made of protons, neutrons, and electrons.\"\n",
    "]\n",
    "for text in neutral_samples:\n",
    "    exploration_texts.append(text)\n",
    "    exploration_labels.append('neutral')\n",
    "\n",
    "print(f\"\\nDataset composition:\")\n",
    "print(f\"  Total samples: {len(exploration_texts)}\")\n",
    "print(f\"  Categories: {len(set(exploration_labels))}\")\n",
    "for category in set(exploration_labels):\n",
    "    count = exploration_labels.count(category)\n",
    "    print(f\"    {category}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb0543",
   "metadata": {
    "id": "dbdb0543"
   },
   "source": [
    "## **Question 1:** Exploring Pooling Strategies (15 points)\n",
    "\n",
    "This question explores how different **pooling methods** affect a model's ability to distinguish between conceptual categories (e.g., safe vs. unsafe). You will analyze the hidden states from each layer of a language model to find the best approach.\n",
    "\n",
    "### **Key Concepts**\n",
    "\n",
    "* **Pooling**: The process of converting the hidden states for all tokens in an input into a single representative vector. You will test four methods:\n",
    "    * **`last`**: Use the final token's hidden state.\n",
    "    * **`mean`**: Average the hidden states of all tokens.\n",
    "    * **`max`**: Take the element-wise maximum across all token hidden states.\n",
    "    * **`first`**: Use the first token's hidden state (often a special `[CLS]` token).\n",
    "\n",
    "* **Separation (Sep)**: A metric that measures how well the model's representations distinguish between categories. It's calculated as `Within-Category Similarity - Between-Category Similarity`.\n",
    "    * A high separation score (e.g., > 0.3) indicates that representations for the same category are tightly clustered while representations for different categories are far apart.\n",
    "\n",
    "### Tasks:\n",
    "- Experiment with different pooling methods: 'last', 'mean', 'max', and 'first'.\n",
    "- For each method, generate the neural landscape visualization and record the separation (Sep) values for each layer.\n",
    "- Compare how pooling strategies affect category separation across layers.\n",
    "- Identify the layer that provides the strongest category separation.\n",
    "- Recommend the most effective pooling method for this task, explaining your reasoning.\n",
    "\n",
    "### ANALYSIS:\n",
    "-\tWhich pooling method yields the highest average separation (Sep) across layers?\n",
    "-\tWhich layer demonstrates the most distinct clustering between categories?\n",
    "      (Note: SmolLM has 24 layers numbered 0-23)\n",
    "-\tBased on your findings, which pooling strategy would you recommend and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009c540",
   "metadata": {
    "id": "q1_pooling_experiment"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: Question 1 - Pooling Strategy Experiment\n",
    "# ============================================================\n",
    "# Test each pooling method and record separation scores\n",
    "\n",
    "pooling_methods = ['last', 'mean', 'max', 'first']\n",
    "pooling_results = {}\n",
    "\n",
    "for pooling_method in pooling_methods:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing pooling method: {pooling_method}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # YOUR CODE HERE: Extract hidden states with this pooling method\n",
    "    # Hint: Use get_hidden_states() with pooling=pooling_method\n",
    "    # hidden_states = get_hidden_states(...)\n",
    "    \n",
    "    # YOUR CODE HERE: Visualize the neural landscape\n",
    "    # Hint: Use visualize_neural_landscape()\n",
    "    \n",
    "    # YOUR CODE HERE: Record the separation scores for each layer\n",
    "    # Store in pooling_results[pooling_method] = {...}\n",
    "    pass\n",
    "\n",
    "# YOUR ANALYSIS HERE (answer the 3 questions in markdown cell below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf302880",
   "metadata": {
    "id": "q1_analysis"
   },
   "source": [
    "### Required Analysis for Question 1\n",
    "\n",
    "Based on your pooling strategy experiments, answer the following:\n",
    "\n",
    "1. **Best Pooling Method (5 points)**: Which pooling method yields the highest average separation (Sep) across layers? Provide specific numbers.\n",
    "\n",
    "2. **Layer Analysis (5 points)**: Which layer demonstrates the most distinct clustering between categories? (Note: SmolLM has 24 layers numbered 0-23). What does this tell you about where safety information is encoded?\n",
    "\n",
    "3. **Recommendation (5 points)**: Based on your findings, which pooling strategy would you recommend for this task and why? Consider both performance and computational efficiency.\n",
    "\n",
    "**YOUR ANALYSIS HERE:**\n",
    "[Write your response here - minimum 4-5 sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98876107",
   "metadata": {
    "id": "98876107"
   },
   "source": [
    "**The Neural Probe: Extracting Hidden States:** This function is our primary tool for examining the model's internal representations. It extracts the activation patterns at different layers of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d63c0",
   "metadata": {
    "id": "bd1d63c0"
   },
   "outputs": [],
   "source": [
    "def get_hidden_states(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    texts: List[str],\n",
    "    layers: List[int] = None,\n",
    "    token_pos: int = -1,\n",
    "    batch_size: int = 8,\n",
    "    max_length: int = 256,\n",
    "    pooling: str = 'last',\n",
    "    return_attention_mask: bool = False,\n",
    "    enable_grad: bool = False,\n",
    "    normalize_activations: bool = False  # ⭐ NEW: Add this parameter\n",
    ") -> Union[Dict[int, np.ndarray], Tuple[Dict[int, np.ndarray], torch.Tensor]]:\n",
    "    \"\"\"\n",
    "    Extract hidden states with multiple pooling strategies.\n",
    "\n",
    "    NEW: normalize_activations - If True, normalize each hidden state to unit norm\n",
    "         This makes separation scores comparable across architectures!\n",
    "    \"\"\"\n",
    "    if layers is None:\n",
    "        layers = list(range(model.config.num_hidden_layers))\n",
    "\n",
    "    all_hidden_states = {layer: [] for layer in layers}\n",
    "    all_attention_masks = [] if return_attention_mask else None\n",
    "\n",
    "    grad_context = torch.enable_grad() if enable_grad else torch.no_grad()\n",
    "\n",
    "    with grad_context:\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"Scanning neural activity\"):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "\n",
    "            inputs = tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            ).to(model.device)\n",
    "\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "            if return_attention_mask:\n",
    "                all_attention_masks.append(inputs.attention_mask.cpu())\n",
    "\n",
    "            for layer_idx in layers:\n",
    "                hidden = outputs.hidden_states[layer_idx]\n",
    "\n",
    "                # Different pooling strategies\n",
    "                if pooling == 'last':\n",
    "                    seq_lens = inputs.attention_mask.sum(dim=1) - 1\n",
    "                    batch_indices = torch.arange(hidden.size(0), device=hidden.device)\n",
    "                    selected_hidden = hidden[batch_indices, seq_lens]\n",
    "\n",
    "                elif pooling == 'mean':\n",
    "                    mask = inputs.attention_mask.unsqueeze(-1).expand(hidden.size()).float()\n",
    "                    selected_hidden = (hidden * mask).sum(dim=1) / mask.sum(dim=1)\n",
    "\n",
    "                elif pooling == 'max':\n",
    "                    mask = inputs.attention_mask.unsqueeze(-1).expand(hidden.size())\n",
    "                    hidden_masked = hidden.clone()\n",
    "                    hidden_masked[~mask.bool()] = -float('inf')\n",
    "                    selected_hidden = hidden_masked.max(dim=1)[0]\n",
    "\n",
    "                elif pooling == 'first':\n",
    "                    selected_hidden = hidden[:, 0]\n",
    "\n",
    "                else:\n",
    "                    selected_hidden = hidden[:, token_pos]\n",
    "\n",
    "                # ⭐ NEW: Normalize activations if requested\n",
    "                if normalize_activations:\n",
    "                    norms = torch.norm(selected_hidden, dim=-1, keepdim=True)\n",
    "                    selected_hidden = selected_hidden / (norms + 1e-8)\n",
    "\n",
    "                # Convert to numpy unless gradients are needed\n",
    "                if enable_grad:\n",
    "                    all_hidden_states[layer_idx].append(selected_hidden)\n",
    "                else:\n",
    "                    all_hidden_states[layer_idx].append(selected_hidden.cpu().float().numpy())\n",
    "\n",
    "            if i % (batch_size * 10) == 0:\n",
    "                clear_memory()\n",
    "\n",
    "    # Stack results\n",
    "    for layer_idx in layers:\n",
    "        if enable_grad:\n",
    "            all_hidden_states[layer_idx] = torch.cat(all_hidden_states[layer_idx], dim=0)\n",
    "        else:\n",
    "            all_hidden_states[layer_idx] = np.vstack(all_hidden_states[layer_idx])\n",
    "\n",
    "    if return_attention_mask:\n",
    "        attention_masks = torch.cat(all_attention_masks, dim=0)\n",
    "        return all_hidden_states, attention_masks\n",
    "\n",
    "    return all_hidden_states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e635c3ff",
   "metadata": {
    "id": "e635c3ff"
   },
   "source": [
    "**Visualizing the Neural Landscape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6383a78",
   "metadata": {
    "id": "c6383a78"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_neural_landscape(hidden_states, labels, layers_to_plot=None):\n",
    "    \"\"\"\n",
    "    Create a visual map of neural activation patterns.\n",
    "\n",
    "    This is like creating an fMRI scan of the model's \"brain\" -\n",
    "    different concepts light up different regions. We're looking for\n",
    "    the emergence of structure: do similar concepts cluster together?\n",
    "    Do different layers organize information differently?\n",
    "    \"\"\"\n",
    "    if layers_to_plot is None:\n",
    "        # Default to plotting the first 6 layers available\n",
    "        layers_to_plot = list(hidden_states.keys())[:6]\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 14))\n",
    "    fig.suptitle(\"Neural Activation Landscape: How Concepts Organize Across Layers\",\n",
    "                 fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Group labels by category for better visualization\n",
    "    label_groups = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        category = label.split('_')[0] if '_' in label else label\n",
    "        if category not in label_groups:\n",
    "            label_groups[category] = []\n",
    "        label_groups[category].append(i)\n",
    "\n",
    "    # Reorder indices by category to group similar concepts together in the plot\n",
    "    ordered_indices = []\n",
    "    ordered_labels = []\n",
    "    for category, indices in sorted(label_groups.items()):\n",
    "        ordered_indices.extend(indices)\n",
    "        ordered_labels.extend([labels[i] for i in indices])\n",
    "\n",
    "    # Store similarity statistics for analysis\n",
    "    similarity_stats = []\n",
    "\n",
    "    for idx, layer in enumerate(layers_to_plot):\n",
    "        plt.subplot(2, 3, idx + 1)\n",
    "\n",
    "        hidden = hidden_states[layer]\n",
    "\n",
    "        # Reorder by category for visual clarity\n",
    "        hidden_ordered = hidden[ordered_indices]\n",
    "\n",
    "        # --- Center the hidden states ---\n",
    "        # Centering the hidden states by subtracting the mean vector is crucial.\n",
    "        # It removes the common \"background\" activation, allowing the cosine\n",
    "        # similarity to focus on the actual semantic differences between concepts.\n",
    "        # This prevents an artificial increase in similarity scores.\n",
    "        hidden_centered = hidden_ordered - hidden_ordered.mean(axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "        # Compute cosine similarity matrix using the centered states\n",
    "        hidden_norm = hidden_centered / (np.linalg.norm(hidden_centered, axis=1, keepdims=True) + 1e-8)\n",
    "        similarity = hidden_norm @ hidden_norm.T\n",
    "\n",
    "        # Calculate within/between group similarities for better scaling and analysis\n",
    "        within_sim = []\n",
    "        between_sim = []\n",
    "        # Create a mapping from original index to its group for easier lookup\n",
    "        index_to_group = {idx: cat for cat, indices in label_groups.items() for idx in indices}\n",
    "\n",
    "        for i in range(len(ordered_indices)):\n",
    "            for j in range(i + 1, len(ordered_indices)):\n",
    "                idx1 = ordered_indices[i]\n",
    "                idx2 = ordered_indices[j]\n",
    "                if index_to_group[idx1] == index_to_group[idx2]:\n",
    "                    within_sim.append(similarity[i, j])\n",
    "                else:\n",
    "                    between_sim.append(similarity[i, j])\n",
    "\n",
    "        # Calculate statistics\n",
    "        within_mean = np.mean(within_sim) if within_sim else 0\n",
    "        between_mean = np.mean(between_sim) if between_sim else 0\n",
    "        separation = within_mean - between_mean\n",
    "\n",
    "        # Enhanced color scaling based on actual data distribution\n",
    "        # Use percentiles to create a robust color map against outliers\n",
    "        sim_flat = similarity[np.triu_indices_from(similarity, k=1)]  # Upper triangle only\n",
    "        vmin = np.percentile(sim_flat, 5)  # 5th percentile\n",
    "        vmax = np.percentile(sim_flat, 95)  # 95th percentile\n",
    "\n",
    "        # If the range is too small, expand it to ensure the visualization is meaningful\n",
    "        if vmax - vmin < 0.1:\n",
    "            mean_sim = np.mean(sim_flat)\n",
    "            range_expand = max(0.2, (vmax - vmin) * 2)\n",
    "            vmin = mean_sim - range_expand / 2\n",
    "            vmax = mean_sim + range_expand / 2\n",
    "\n",
    "        # Create clustered heatmap with enhanced scaling\n",
    "        im = plt.imshow(similarity, cmap='RdBu_r', vmin=vmin, vmax=vmax, aspect='auto')\n",
    "        plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "\n",
    "        # Add category dividers to make the structure more visible\n",
    "        current_pos = 0\n",
    "        for category, indices in sorted(label_groups.items()):\n",
    "            next_pos = current_pos + len(indices)\n",
    "            if next_pos < len(ordered_labels):\n",
    "                plt.axhline(y=next_pos - 0.5, color='green', linewidth=2, alpha=0.7)\n",
    "                plt.axvline(x=next_pos - 0.5, color='green', linewidth=2, alpha=0.7)\n",
    "            current_pos = next_pos\n",
    "\n",
    "        # Title with summary statistics\n",
    "        plt.title(f\"Layer {layer}: {'Early' if layer < 8 else 'Middle' if layer < 16 else 'Late'}\\n\" +\n",
    "                  f\"Sep={separation:.3f} (W:{within_mean:.3f}, B:{between_mean:.3f})\",\n",
    "                  fontsize=10)\n",
    "\n",
    "        # Add category labels on y-axis for readability\n",
    "        category_positions = []\n",
    "        category_names = []\n",
    "        current_pos = 0\n",
    "        for category, indices in sorted(label_groups.items()):\n",
    "            mid_point = current_pos + len(indices) // 2\n",
    "            category_positions.append(mid_point)\n",
    "            category_names.append(category)\n",
    "            current_pos += len(indices)\n",
    "\n",
    "        plt.yticks(category_positions, category_names, fontsize=8)\n",
    "        plt.xticks([])\n",
    "\n",
    "        # Add text annotation to highlight key observations\n",
    "        if idx == 0: # First plotted layer\n",
    "            plt.text(0.02, 0.98, 'Token-level\\nprocessing',\n",
    "                     transform=plt.gca().transAxes, fontsize=8,\n",
    "                     verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "                                                        facecolor='wheat', alpha=0.5))\n",
    "        elif idx == len(layers_to_plot) - 1: # Last plotted layer\n",
    "            plt.text(0.02, 0.98, f'Semantic\\nclusters\\n(vmin:{vmin:.2f})',\n",
    "                     transform=plt.gca().transAxes, fontsize=8,\n",
    "                     verticalalignment='top', bbox=dict(boxstyle='round',\n",
    "                                                        facecolor='lightgreen', alpha=0.5))\n",
    "\n",
    "        similarity_stats.append({\n",
    "            'layer': layer,\n",
    "            'within_sim': within_mean,\n",
    "            'between_sim': between_mean,\n",
    "            'separation': separation,\n",
    "            'vmin': vmin,\n",
    "            'vmax': vmax,\n",
    "            'range': vmax - vmin\n",
    "        })\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle\n",
    "    plt.savefig('results/visualizations/neural_landscape_centered.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Print insights with statistics\n",
    "    print(\"\\nKEY OBSERVATIONS FROM NEURAL LANDSCAPE (WITH CENTERING):\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"Similarity Statistics by Layer:\")\n",
    "    for stat in similarity_stats:\n",
    "        print(f\"  Layer {stat['layer']:2d}: Separation={stat['separation']:+.4f} \"\n",
    "              f\"(Within={stat['within_sim']:.4f}, Between={stat['between_sim']:.4f}) \"\n",
    "              f\"Range=[{stat['vmin']:.3f}, {stat['vmax']:.3f}]\")\n",
    "\n",
    "    # Note about small sample size\n",
    "    if len(labels) < 50:\n",
    "        print(f\"\\nNote: Only {len(labels)} samples. Increase sample size for clearer patterns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f677a",
   "metadata": {
    "id": "ba0f677a"
   },
   "source": [
    "\n",
    "**ANALYSIS WITH: SmolLM-1.7B-Instruct (24 layers)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7233d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 949
    },
    "id": "b1e7233d",
    "outputId": "e567dd9e-8059-45b0-9f52-052f02629d1a"
   },
   "outputs": [],
   "source": [
    "# Extract hidden states with different pooling strategies\n",
    "# Recalculate layer config for current model to avoid stale config\n",
    "LAYER_CONFIG = get_layer_ranges(model)\n",
    "exploration_layers = LAYER_CONFIG['exploration']\n",
    "print(f\"Exploring layers: {exploration_layers}\")\n",
    "print(f\"  Early: {LAYER_CONFIG['early']}\")\n",
    "print(f\"  Middle: {LAYER_CONFIG['middle']}\")\n",
    "print(f\"  Late: {LAYER_CONFIG['late']}\")\n",
    "\n",
    "# Try different pooling methods\n",
    "pooling_method = 'last'  # Change this to test: 'last', 'mean', 'max', 'first'\n",
    "print(f\"\\nExtracting hidden states using '{pooling_method}' pooling...\")\n",
    "exploration_hidden = get_hidden_states(\n",
    "    model, tokenizer, exploration_texts,\n",
    "    layers=exploration_layers, batch_size=8,\n",
    "    pooling=pooling_method\n",
    ")\n",
    "visualize_neural_landscape(exploration_hidden, exploration_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63437730",
   "metadata": {
    "id": "63437730"
   },
   "source": [
    "### Discovering Emergent Structure: The Geometry of Thought\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7846b27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "b7846b27",
    "outputId": "04047213-1b55-49a0-c450-a881e8ad8bdd"
   },
   "outputs": [],
   "source": [
    "def analyze_representation_geometry(hidden_states, labels):\n",
    "    \"\"\"\n",
    "    Analyze the geometric structure of representations.\n",
    "\n",
    "    In neuroscience, we've discovered that the brain organizes similar\n",
    "    concepts in nearby regions. This function tests if language models\n",
    "    exhibit the same property. We measure:\n",
    "    - Within-category similarity (how close are examples of the same type?)\n",
    "    - Between-category similarity (how separated are different types?)\n",
    "    - Emergence of structure (does organization improve with depth?)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for layer in hidden_states.keys():\n",
    "        H = hidden_states[layer]\n",
    "\n",
    "        # Normalize for angular distance\n",
    "        H_norm = H / (np.linalg.norm(H, axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "        # Compute category statistics\n",
    "        unique_labels = list(set(labels))\n",
    "        category_map = {label: np.array([l == label for l in labels]) for label in unique_labels}\n",
    "\n",
    "        # Within-category similarity\n",
    "        within_sims = []\n",
    "        for label, mask in category_map.items():\n",
    "            if mask.sum() > 1:\n",
    "                category_hidden = H_norm[mask]\n",
    "                sims = category_hidden @ category_hidden.T\n",
    "                # Get upper triangle (excluding diagonal)\n",
    "                upper_triangle = np.triu_indices(sims.shape[0], k=1)\n",
    "                within_sims.extend(sims[upper_triangle])\n",
    "\n",
    "        # Between-category similarity\n",
    "        between_sims = []\n",
    "        label_list = list(category_map.keys())\n",
    "        for i, label1 in enumerate(label_list):\n",
    "            for label2 in label_list[i+1:]:\n",
    "                mask1 = category_map[label1]\n",
    "                mask2 = category_map[label2]\n",
    "                if mask1.sum() > 0 and mask2.sum() > 0:\n",
    "                    sims = H_norm[mask1] @ H_norm[mask2].T\n",
    "                    between_sims.extend(sims.flatten())\n",
    "\n",
    "        within_mean = np.mean(within_sims) if within_sims else 0\n",
    "        between_mean = np.mean(between_sims) if between_sims else 0\n",
    "        separation = within_mean - between_mean\n",
    "\n",
    "        # Compute cluster quality metric (silhouette coefficient approximation)\n",
    "        cluster_quality = (within_mean - between_mean) / max(within_mean, between_mean) if max(within_mean, between_mean) > 0 else 0\n",
    "\n",
    "        results.append({\n",
    "            'layer': layer,\n",
    "            'within_similarity': within_mean,\n",
    "            'between_similarity': between_mean,\n",
    "            'separation_score': separation,\n",
    "            'cluster_quality': cluster_quality\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "geometry_results = analyze_representation_geometry(exploration_hidden, exploration_labels)\n",
    "\n",
    "# Visualize the emergence of structure with enhanced insights\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "layers = [r['layer'] for r in geometry_results]\n",
    "within = [r['within_similarity'] for r in geometry_results]\n",
    "between = [r['between_similarity'] for r in geometry_results]\n",
    "separation = [r['separation_score'] for r in geometry_results]\n",
    "\n",
    "# Plot 1: Similarity evolution\n",
    "ax = axes[0]\n",
    "ax.plot(layers, within, 'o-', label='Within Category', color='green', linewidth=2, markersize=8)\n",
    "ax.plot(layers, between, 's-', label='Between Categories', color='red', linewidth=2, markersize=8)\n",
    "ax.fill_between(layers, between, within, alpha=0.2, color='green')\n",
    "ax.set_xlabel('Layer Depth', fontsize=12)\n",
    "ax.set_ylabel('Average Cosine Similarity', fontsize=12)\n",
    "ax.set_title('Emergence of Categorical Structure', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Plot 2: Separation score\n",
    "ax = axes[1]\n",
    "ax.plot(layers, separation, 'o-', color='purple', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Layer Depth', fontsize=12)\n",
    "ax.set_ylabel('Separation Score', fontsize=12)\n",
    "ax.set_title('Concept Separation Across Layers', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax.fill_between(layers, 0, separation, alpha=0.3, color='purple')\n",
    "\n",
    "# Mark regions of processing (24 layers total)\n",
    "ax.axvspan(0, 5, alpha=0.1, color='blue')\n",
    "ax.text(2.5, ax.get_ylim()[1]*0.9, 'Syntactic', ha='center', fontsize=10)\n",
    "ax.axvspan(6, 15, alpha=0.1, color='green')\n",
    "ax.text(10.5, ax.get_ylim()[1]*0.9, 'Semantic', ha='center', fontsize=10)\n",
    "ax.axvspan(16, 23, alpha=0.1, color='red')\n",
    "ax.text(19.5, ax.get_ylim()[1]*0.9, 'Abstract', ha='center', fontsize=10)\n",
    "\n",
    "plt.suptitle('The Geometry of Thought: How Structure Emerges in Neural Networks',\n",
    "            fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/visualizations/representation_geometry.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c4bb3",
   "metadata": {
    "id": "720c4bb3"
   },
   "source": [
    "## **Question 2:** PCA Implementation & Validation (20 points)\n",
    "\n",
    "### Understanding the Mathematics of Dimensionality Reduction\n",
    "\n",
    "Let's implement PCA ourselves to discover structure in high-dimensional data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0a8080",
   "metadata": {
    "id": "bb0a8080"
   },
   "source": [
    "### Your Tasks:\n",
    "1. Complete the implementation of pca_from_scratch() and project_onto_components() functions.\n",
    "Follow the provided step-by-step comments in the code template.\n",
    "2. Run validate_pca_implementation() to test your PCA against several correctness checks (mean centering, orthogonality, normalization, etc.).\n",
    "3. Ensure your PCA implementation passes at least 4 out of 5 tests to receive full credit.\n",
    "\n",
    "\n",
    "### Required Analysis (5 points):\n",
    "\n",
    "Answer the following questions briefly:\n",
    "\n",
    "1. **Data Centering (2 points)**: Why do we center the data before computing PCA?\n",
    "\n",
    "2. **Explained Variance (2 points)**: What does the explained variance ratio represent in PCA?\n",
    "\n",
    "3. **Equal Eigenvalues (1 point)**: If two components have almost equal eigenvalues, what does that indicate about the data structure?\n",
    "\n",
    "**YOUR ANALYSIS HERE:**\n",
    "[Write your response here - 3-4 sentences minimum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950c5ff5",
   "metadata": {
    "id": "950c5ff5"
   },
   "outputs": [],
   "source": [
    "def pca_from_scratch(H: np.ndarray, n_components: int = 2) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    TODO: Complete the PCA implementation.\n",
    "\n",
    "    Principal Component Analysis finds the directions of maximum variance\n",
    "    in your data. These directions often correspond to meaningful concepts.\n",
    "\n",
    "    Steps to implement:\n",
    "    1. Center the data (subtract mean)\n",
    "    2. Compute covariance matrix\n",
    "    3. Find eigenvalues and eigenvectors\n",
    "    4. Sort by importance (largest eigenvalue first)\n",
    "    5. Select top components\n",
    "    6. Normalize eigenvectors to unit length\n",
    "\n",
    "    Args:\n",
    "        H: Data matrix (n_samples, n_features)\n",
    "        n_components: Number of components to keep\n",
    "\n",
    "    Returns:\n",
    "        components: Principal directions (n_components, n_features)\n",
    "        mean: Mean of original data\n",
    "        explained_variance_ratio: Fraction of variance explained by each component\n",
    "    \"\"\"\n",
    "    # Step 1: Center the data (remove mean)\n",
    "    # TODO: Compute the mean along axis 0 and subtract it\n",
    "       # YOUR CODE HERE\n",
    "       # YOUR CODE HERE\n",
    "\n",
    "    # Step 2: Compute covariance matrix\n",
    "    # Cov = (1/(n-1)) * X^T @ X\n",
    "    n_samples = H.shape[0]\n",
    "       # YOUR CODE HERE\n",
    "\n",
    "    # Step 3: Find eigenvalues and eigenvectors\n",
    "    # The eigenvectors of the covariance matrix are the principal components\n",
    "    # Hint: use np.linalg.eigh for symmetric matrices\n",
    "       # YOUR CODE HERE\n",
    "\n",
    "    # Step 4: Sort by importance (largest eigenvalue first)\n",
    "    # TODO: Get indices that would sort eigenvalues in descending order\n",
    "       # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "    # Step 5: Select top components and ensure they're unit vectors\n",
    "       # YOUR CODE HERE - select and transpose\n",
    "\n",
    "    # Step 6: Calculate explained variance ratio\n",
    "       # YOUR CODE HERE\n",
    "\n",
    "    return components, mean, explained_variance_ratio\n",
    "\n",
    "def project_onto_components(H: np.ndarray, components: np.ndarray, mean: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Project data onto discovered components.\n",
    "\n",
    "    Args:\n",
    "        H: Data to project\n",
    "        components: Principal components (rows are components)\n",
    "        mean: Mean to center data\n",
    "\n",
    "    Returns:\n",
    "        Projected data in component space\n",
    "    \"\"\"\n",
    "    H_centered = H - mean\n",
    "    return H_centered @ components.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337a511f",
   "metadata": {
    "id": "337a511f"
   },
   "source": [
    "**Validation for PCA**:\n",
    "\n",
    "Test your PCA implementation to ensure correctness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ad7e0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91ad7e0d",
    "outputId": "c8890aa5-0946-4f1d-fad4-00af44f16c17"
   },
   "outputs": [],
   "source": [
    "def validate_pca_implementation():\n",
    "    \"\"\"\n",
    "    Unit tests for PCA implementation.\n",
    "    This will verify your implementation is correct.\n",
    "    \"\"\"\n",
    "    print(\"Running PCA validation tests...\")\n",
    "    tests_passed = []\n",
    "\n",
    "    try:\n",
    "        # Test 1: Known covariance matrix\n",
    "        X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "        components, mean, var_ratio = pca_from_scratch(X, n_components=2)\n",
    "\n",
    "        # Test mean centering\n",
    "        assert np.allclose(mean, X.mean(axis=0)), \"Mean calculation incorrect\"\n",
    "        tests_passed.append(\"mean_centering\")\n",
    "        print(\"  Test 1 passed: Mean centering\")\n",
    "\n",
    "        # Test 2: Components are orthogonal\n",
    "        if len(components) > 1:\n",
    "            dot_product = np.dot(components[0], components[1])\n",
    "            assert np.abs(dot_product) < 1e-10, \"Components not orthogonal\"\n",
    "            tests_passed.append(\"orthogonality\")\n",
    "            print(\"  Test 2 passed: Orthogonality\")\n",
    "\n",
    "        # Test 3: Components have unit norm\n",
    "        for i, comp in enumerate(components):\n",
    "            norm = np.linalg.norm(comp)\n",
    "            assert np.allclose(norm, 1.0), f\"Component {i} not unit norm (norm={norm})\"\n",
    "        tests_passed.append(\"unit_norm\")\n",
    "        print(\"  Test 3 passed: Unit norm\")\n",
    "\n",
    "        # Test 4: Variance ratio sums to <= 1\n",
    "        assert var_ratio.sum() <= 1.01, \"Variance ratio exceeds 1\"\n",
    "        tests_passed.append(\"variance_sum\")\n",
    "        print(\"  Test 4 passed: Variance sum\")\n",
    "\n",
    "        # Test 5: Eigenvalues are sorted in descending order\n",
    "        I = np.eye(5)\n",
    "        comp_I, mean_I, var_I = pca_from_scratch(I, n_components=3)\n",
    "        assert all(var_I[i] >= var_I[i+1] for i in range(len(var_I)-1)), \"Eigenvalues not sorted correctly\"\n",
    "        tests_passed.append(\"sorting\")\n",
    "        print(\"  Test 5 passed: Sorting\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Test failed with error: {e}\")\n",
    "\n",
    "    score = len(tests_passed) / 5\n",
    "    print(f\"\\nPCA Implementation Score: {len(tests_passed)}/5 tests passed ({score*100:.0f}%)\")\n",
    "    print(f\"Tests passed: {tests_passed}\")\n",
    "\n",
    "    # Assertion for grading\n",
    "    assert score >= 0.8, \"PCA implementation needs more work (less than 80% tests passed)\"\n",
    "\n",
    "    return score\n",
    "\n",
    "# Run validation - this must pass for full credit\n",
    "pca_validation_score = validate_pca_implementation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a502a90b",
   "metadata": {
    "id": "a502a90b"
   },
   "source": [
    "## **Question 3:** K-Means Clustering Analysis (20 points)\n",
    "\n",
    "### Discovering Natural Groupings with K-Means\n",
    "\n",
    "Compare how well K-means clustering can discover emotion categories with and without dimensionality reduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768b697",
   "metadata": {
    "id": "6768b697"
   },
   "outputs": [],
   "source": [
    "def kmeans_from_scratch(X: np.ndarray, n_clusters: int, max_iters: int = 100, random_state: int = 42) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    TODO: Implement the K-Means clustering algorithm from scratch.\n",
    "\n",
    "    Steps:\n",
    "    1. Initialize centroids: Randomly select 'n_clusters' points from X as initial centroids.\n",
    "       (Hint: Use np.random.RandomState(random_state).permutation)\n",
    "    2. Loop for 'max_iters':\n",
    "       a. Assign clusters: For each point, find the nearest centroid (use Euclidean distance).\n",
    "          (Hint: np.linalg.norm(point - centroid, axis=1))\n",
    "       b. Update centroids: Compute the mean of all points assigned to each cluster.\n",
    "    3. Return the final centroids and the cluster assignments (labels) for each point.\n",
    "\n",
    "    Args:\n",
    "        X: Data matrix (n_samples, n_features)\n",
    "        n_clusters: The number of clusters (K)\n",
    "        max_iters: Maximum number of iterations\n",
    "        random_state: Seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "        centroids: Final cluster centroids (n_clusters, n_features)\n",
    "        labels: Cluster assignment for each point (n_samples,)\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # --- YOUR CODE HERE ---\n",
    "\n",
    "    # Step 1: Initialize centroids\n",
    "    # Hint: Randomly select indices\n",
    "     \n",
    "\n",
    "    labels = np.zeros(n_samples)\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        # Step 2a: Assign clusters\n",
    "        for i in range(n_samples):\n",
    "            # Calculate distances from point i to all centroids\n",
    "            distances =  \n",
    "            # Assign to closest centroid\n",
    "            labels[i] =  \n",
    "\n",
    "        # Step 2b: Update centroids\n",
    "        new_centroids = np.zeros((n_clusters, n_features))\n",
    "        for k in range(n_clusters):\n",
    "            cluster_points =  \n",
    "            if len(cluster_points) > 0:\n",
    "                new_centroids[k] =  \n",
    "            else:\n",
    "                # Re-initialize empty clusters\n",
    "                new_centroids[k] = \n",
    "\n",
    "        # Check for convergence (if centroids don't change)\n",
    "        if np.allclose(centroids, new_centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "\n",
    "    # --- END YOUR CODE ---\n",
    "\n",
    "    return centroids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35556a1c",
   "metadata": {
    "id": "35556a1c"
   },
   "outputs": [],
   "source": [
    "def kmeans_emotion_analysis(emotion_hidden, emotion_labels, layer=20):\n",
    "    \"\"\"\n",
    "    TODO: Compare clustering approaches for emotion discovery.\n",
    "\n",
    "    Tasks:\n",
    "    1. Apply K-means directly to raw hidden states\n",
    "    2. Apply PCA first, then K-means on reduced features\n",
    "    3. Compare clustering quality using Adjusted Rand Index (ARI)\n",
    "    4. Analyze which emotions cluster well together\n",
    "\n",
    "    Expected outputs:\n",
    "    - ARI scores for both approaches\n",
    "    - Silhouette scores for cluster quality\n",
    "    - Confusion matrix showing predicted vs true labels\n",
    "\n",
    "    Evaluation Metrics:\n",
    "    - adjusted_rand_score: Measures agreement between true and predicted labels\n",
    "      (see: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html)\n",
    "    - silhouette_score: Measures cluster cohesion and separation\n",
    "      (see: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with clustering metrics and analysis\n",
    "    \"\"\"\n",
    "    from sklearn.cluster import KMeans # Note: You can use this for comparison, but you are requried to implement KMeans yourself!!\n",
    "    from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "    # Note: While you are not required to implement these scores\n",
    "    # Visit the documentation links above to understand how these metrics are calculated and what they measure.\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Get hidden states for specified layer\n",
    "    H_emotions = emotion_hidden[layer]\n",
    "\n",
    "    # Map emotion labels to integers for evaluation\n",
    "    unique_emotions = list(set(emotion_labels))\n",
    "    emotion_to_id = {e: i for i, e in enumerate(unique_emotions)}\n",
    "    true_labels = np.array([emotion_to_id[e] for e in emotion_labels])\n",
    "    n_emotions = len(unique_emotions)\n",
    "\n",
    "    # TODO: Task 1 - Direct K-means on raw features\n",
    "    # Apply K-means with n_clusters=n_emotions\n",
    "    #YOUR Implementation\n",
    "    centroids_raw, clusters_raw =  \n",
    "\n",
    "    #REFERENCE FOR COMPARISON\n",
    "    kmeans_raw_sklearn =    # YOUR CODE HERE\n",
    "    clusters_raw_sklearn =    # YOUR CODE HERE\n",
    "\n",
    "    # TODO: Task 2 - PCA + K-means\n",
    "    # First reduce dimensions with PCA (try n_components=10)\n",
    "    # Then apply K-means\n",
    "    n_pca_components = min(10, H_emotions.shape[0] - 1)\n",
    "    components, mean, var_ratio =    # YOUR CODE HERE - use your pca_from_scratch\n",
    "    H_pca =   # YOUR CODE HERE - project data\n",
    "\n",
    "    #YOUR KMEANS IMPLEMENTATION\n",
    "    centroids_pca, clusters_pca = kmeans_from_scratch(H_pca, n_clusters=n_emotions, random_state=42)\n",
    "    #REFENRENCE FOR COMPARISON\n",
    "    kmeans_pca_sklearn =    # YOUR CODE HERE\n",
    "    clusters_pca_sklearn =    # YOUR CODE HERE\n",
    "\n",
    "    # TODO: Task 3 - Compute metrics\n",
    "    # Use adjusted_rand_score and silhouette_score\n",
    "    # --- Metrics for YOUR implementation (for grading) ---\n",
    "    results['raw_ari'] =   # YOUR CODE HERE\n",
    "    results['pca_ari'] =   # YOUR CODE HERE\n",
    "    results['raw_silhouette'] =    # YOUR CODE HERE\n",
    "    results['pca_silhouette'] =    # YOUR CODE HERE\n",
    "    # --- Metrics for sklearn reference (for your comparison) ---\n",
    "    results['raw_ari_sklearn'] = adjusted_rand_score(true_labels, clusters_raw_sklearn)\n",
    "    results['pca_ari_sklearn'] = adjusted_rand_score(true_labels, clusters_pca_sklearn)\n",
    "    results['raw_silhouette_sklearn'] = silhouette_score(H_emotions, clusters_raw_sklearn)\n",
    "    results['pca_silhouette_sklearn'] = silhouette_score(H_pca, clusters_pca_sklearn)\n",
    "\n",
    "    # Determine winner\n",
    "    results['best_method'] = 'raw' if results['raw_ari'] > results['pca_ari'] else 'pca'\n",
    "\n",
    "    # Validation assertions\n",
    "    assert results['raw_ari'] > -0.1, \"ARI too low - check K-means implementation\"\n",
    "    assert results['raw_silhouette'] > 0, \"Silhouette score invalid\"\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78f3e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf78f3e7",
    "lines_to_next_cell": 2,
    "outputId": "0df3e09b-cc20-4c6c-8bb4-619ffb17fcc9"
   },
   "outputs": [],
   "source": [
    "# Prepare emotion data for clustering\n",
    "emotion_texts = []\n",
    "emotion_labels_clustering = []\n",
    "\n",
    "for emotion in ['joy', 'sadness', 'anger', 'fear']:\n",
    "    if emotion in emotion_data:\n",
    "        for scenario in emotion_data[emotion][:200]:  # 100 samples per emotion\n",
    "            emotion_texts.append(scenario)\n",
    "            emotion_labels_clustering.append(emotion)\n",
    "\n",
    "print(f\"Prepared {len(emotion_texts)} emotional examples for clustering\")\n",
    "\n",
    "# Extract hidden states\n",
    "# Use late layers for abstract emotion concepts\n",
    "# Recalculate layer config for current model\n",
    "LAYER_CONFIG = get_layer_ranges(model)\n",
    "emotion_clustering_layers = LAYER_CONFIG['late'][-3:]  # Last 3 late layers\n",
    "print(f\"Using late layers for emotion clustering: {emotion_clustering_layers}\")\n",
    "emotion_hidden_clustering = get_hidden_states(\n",
    "    model, tokenizer, emotion_texts,\n",
    "    layers=emotion_clustering_layers, batch_size=16\n",
    ")\n",
    "\n",
    "# Run K-means analysis\n",
    "# Use the middle layer from the extracted layers\n",
    "analysis_layer = emotion_clustering_layers[len(emotion_clustering_layers)//2]\n",
    "kmeans_results = kmeans_emotion_analysis(\n",
    "    emotion_hidden_clustering,\n",
    "    emotion_labels_clustering,\n",
    "    layer=analysis_layer  # Use one of the extracted layers\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\nK-Means Clustering Results:\")\n",
    "print(f\"Raw features ARI: {kmeans_results['raw_ari']:.3f}\")\n",
    "print(f\"PCA features ARI: {kmeans_results['pca_ari']:.3f}\")\n",
    "print(f\"Raw silhouette: {kmeans_results['raw_silhouette']:.3f}\")\n",
    "print(f\"PCA silhouette: {kmeans_results['pca_silhouette']:.3f}\")\n",
    "print(f\"Best method: {kmeans_results['best_method']}\")\n",
    "\n",
    "print(f\"\\n--- SKLEARN REFERENCE (Layer {analysis_layer}) ---\")\n",
    "print(f\"  Raw features ARI: {kmeans_results['raw_ari_sklearn']:.3f}\")\n",
    "print(f\"  PCA features ARI: {kmeans_results['pca_ari_sklearn']:.3f}\")\n",
    "print(f\"  Raw silhouette: {kmeans_results['raw_silhouette_sklearn']:.3f}\")\n",
    "print(f\"  PCA silhouette: {kmeans_results['pca_silhouette_sklearn']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16487f9d",
   "metadata": {
    "id": "16487f9d"
   },
   "source": [
    "### Required Analysis for Question 3 (5 points)\n",
    "\n",
    "Based on your K-means clustering results, answer the following:\n",
    "\n",
    "1. **Performance Comparison (2 points)**: Compare the performance of PCA-based vs raw clustering. What factors might explain the difference in performance? Consider both the nature of the data and the properties of each approach.\n",
    "\n",
    "2. **Confusion Patterns (2 points)**: Examine which emotion pairs are frequently confused. What patterns do you notice? How might these confusions relate to psychological theories of emotion (e.g., valence-arousal models)?\n",
    "\n",
    "3. **Silhouette Interpretation (1 point)**: Interpret the silhouette scores. What do they reveal about the natural clustering structure of emotions in the model's representation space?\n",
    "\n",
    "**YOUR ANALYSIS HERE:**\n",
    "[Write your response here - minimum 5-6 sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d27e845",
   "metadata": {
    "id": "2d27e845"
   },
   "source": [
    "## Section 2: Unsupervised Discovery - Finding Natural Cognitive Dimensions\n",
    "\n",
    "Now we'll use the PCA implementation to discover how the model naturally organizes information.\n",
    "\n",
    "### Applying PCA to Safety Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee216692",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee216692",
    "outputId": "fefb24f3-5589-4b9d-b7a9-c30200f71aaf"
   },
   "outputs": [],
   "source": [
    "# Prepare safety dataset\n",
    "print(\"Discovering natural safety dimensions...\")\n",
    "\n",
    "safety_texts = []\n",
    "safety_labels = []\n",
    "\n",
    "# Mix safe and unsafe examples from circuit breaker data\n",
    "n_samples = min(500, len(cb_data['train']['prompts']))\n",
    "for i in range(n_samples):\n",
    "    # Unsafe: prompt + unsafe response\n",
    "    unsafe_text = cb_data['train']['prompts'][i] + \" \" + cb_data['train']['unsafe_outputs'][i][:50]\n",
    "    safety_texts.append(unsafe_text)\n",
    "    safety_labels.append('unsafe')\n",
    "\n",
    "    # Safe: prompt + safe response\n",
    "    safe_text = cb_data['train']['prompts'][i] + \" \" + cb_data['train']['safe_outputs'][i][:50]\n",
    "    safety_texts.append(safe_text)\n",
    "    safety_labels.append('safe')\n",
    "\n",
    "print(f\"Prepared {len(safety_texts)} safety examples\")\n",
    "\n",
    "# Extract hidden states\n",
    "# Use exploration layers to match Q6 supervised analysis\n",
    "# Recalculate layer config for current model\n",
    "LAYER_CONFIG = get_layer_ranges(model)\n",
    "safety_pca_layers = LAYER_CONFIG['exploration']  # Use same layers as Q6 for fair comparison\n",
    "print(f\"Using exploration layers for safety PCA: {safety_pca_layers}\")\n",
    "safety_hidden = get_hidden_states(model, tokenizer, safety_texts, layers=safety_pca_layers, batch_size=16)\n",
    "\n",
    "# Apply PCA\n",
    "safety_pca_results = {}\n",
    "for layer in safety_pca_layers:\n",
    "    H = safety_hidden[layer]\n",
    "    components, mean, variance_ratio = pca_from_scratch(H, n_components=10)\n",
    "\n",
    "    safety_pca_results[layer] = {\n",
    "        'components': components,\n",
    "        'mean': mean,\n",
    "        'variance_ratio': variance_ratio,\n",
    "        'projections': project_onto_components(H, components[:2], mean)\n",
    "    }\n",
    "\n",
    "    print(f\"Layer {layer}: Top 2 PCs explain {variance_ratio[:2].sum():.1%} of variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb0d2b6",
   "metadata": {
    "id": "6cb0d2b6"
   },
   "source": [
    "### Applying PCA to Emotion Representations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe1912",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27fe1912",
    "outputId": "00cefe99-1267-4a99-d397-af93daa693a2"
   },
   "outputs": [],
   "source": [
    "# Apply PCA to emotion data\n",
    "print(\"\\nDiscovering natural emotional dimensions...\")\n",
    "\n",
    "emotion_pca_results = {}\n",
    "for layer in emotion_clustering_layers:\n",
    "    H = emotion_hidden_clustering[layer]\n",
    "    components, mean, variance_ratio = pca_from_scratch(H, n_components=10)\n",
    "\n",
    "    emotion_pca_results[layer] = {\n",
    "        'components': components,\n",
    "        'mean': mean,\n",
    "        'variance_ratio': variance_ratio,\n",
    "        'projections': project_onto_components(H, components[:2], mean)\n",
    "    }\n",
    "\n",
    "    print(f\"Layer {layer}: Top 2 PCs explain {variance_ratio[:2].sum():.1%} of variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ec08b9",
   "metadata": {
    "id": "e1ec08b9"
   },
   "source": [
    "## **Question 4:** Discovering Natural Emotional Dimensions (15 points)\n",
    "\n",
    "**This is an ANALYSIS-ONLY question** - no new code implementation required.\n",
    "\n",
    "Using the PCA visualizations already generated above for emotions, analyze and answer:\n",
    "\n",
    "### Required Analysis (15 points):\n",
    "\n",
    "1. **Separation Quality (4 points)**: How well do the discovered principal components separate different classes? Compare safe/unsafe separation to emotion category separation.\n",
    "\n",
    "2. **Variance vs Usefulness (4 points)**: Emotions show higher variance explained in PC1 compared to safety. Does higher variance mean the components are more useful for distinguishing categories? Why or why not?\n",
    "\n",
    "3. **What is PCA Finding? (4 points)**: If the emotion PCs don't cleanly separate emotion categories, what might they be capturing instead? Consider other sources of variation in the data (e.g., sentence length, topic, writing style, sentiment intensity).\n",
    "\n",
    "4. **Comparison to Q3 (3 points)**: Does this explain why K-means struggled in Q3? When might unsupervised discovery work well vs poorly?\n",
    "\n",
    "**Write your analysis below (minimum 5-7 sentences total):**\n",
    "\n",
    "**YOUR ANALYSIS HERE:**\n",
    "[Write your response here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c30498",
   "metadata": {
    "id": "e0c30498"
   },
   "source": [
    "### Enhanced PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9383701",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "c9383701",
    "outputId": "54bb2704-6e80-40a0-babc-3997081e209c"
   },
   "outputs": [],
   "source": [
    "def visualize_pca_discoveries(safety_results, emotion_results, layer=None):\n",
    "    \"\"\"\n",
    "    Visualize PCA discoveries. If layer is None, uses the last layer from LAYER_CONFIG.\n",
    "    \"\"\"\n",
    "    if layer is None:\n",
    "        layer = LAYER_CONFIG['last_layer']\n",
    "    \"\"\"\n",
    "    Visualize the natural dimensions discovered by PCA.\n",
    "\n",
    "    Essential plots:\n",
    "    - 2D scatter plots showing PC1 vs PC2 for safety and emotions\n",
    "    - Variance explained to understand dimensionality\n",
    "    - PC1 distribution to quantify separation quality\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Safety PCA visualization\n",
    "    ax = plt.subplot(1, 4, 1)\n",
    "    projections = safety_results[layer]['projections']\n",
    "    colors = ['red' if l == 'unsafe' else 'green' for l in safety_labels]\n",
    "    scatter = ax.scatter(projections[:, 0], projections[:, 1], c=colors, alpha=0.5, s=20)\n",
    "    ax.set_xlabel(f'PC1 ({safety_results[layer][\"variance_ratio\"][0]:.1%} var)')\n",
    "    ax.set_ylabel(f'PC2 ({safety_results[layer][\"variance_ratio\"][1]:.1%} var)')\n",
    "    ax.set_title('Safety: Natural Dimensions')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add decision boundary\n",
    "    from sklearn.svm import SVC\n",
    "    svm = SVC(kernel='linear')\n",
    "    y = [1 if l == 'safe' else 0 for l in safety_labels]\n",
    "    svm.fit(projections[:, :2], y)\n",
    "\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    xx, yy = np.meshgrid(np.linspace(xlim[0], xlim[1], 50),\n",
    "                         np.linspace(ylim[0], ylim[1], 50))\n",
    "    Z = svm.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contour(xx, yy, Z, colors='k', levels=[0], alpha=0.5, linestyles=['--'])\n",
    "\n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor='red', alpha=0.5, label='Unsafe'),\n",
    "                      Patch(facecolor='green', alpha=0.5, label='Safe')]\n",
    "    ax.legend(handles=legend_elements, loc='best')\n",
    "\n",
    "    # Emotion PCA visualization\n",
    "    ax = plt.subplot(1, 4, 2)\n",
    "    projections = emotion_results[layer]['projections']\n",
    "    emotion_colors = {'joy': 'yellow', 'sadness': 'blue', 'anger': 'red', 'fear': 'purple'}\n",
    "    colors = [emotion_colors.get(l, 'gray') for l in emotion_labels_clustering]\n",
    "    ax.scatter(projections[:, 0], projections[:, 1], c=colors, alpha=0.5, s=20)\n",
    "    ax.set_xlabel(f'PC1 ({emotion_results[layer][\"variance_ratio\"][0]:.1%} var)')\n",
    "    ax.set_ylabel(f'PC2 ({emotion_results[layer][\"variance_ratio\"][1]:.1%} var)')\n",
    "    ax.set_title('Emotions: Natural Dimensions')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add emotion centroids with labels\n",
    "    for emotion in emotion_colors.keys():\n",
    "        mask = [l == emotion for l in emotion_labels_clustering]\n",
    "        if any(mask):\n",
    "            emotion_proj = projections[mask]\n",
    "            centroid = emotion_proj.mean(axis=0)\n",
    "            ax.scatter(centroid[0], centroid[1], s=200, c=emotion_colors[emotion],\n",
    "                      edgecolors='black', linewidth=2, marker='*')\n",
    "            ax.annotate(emotion, (centroid[0], centroid[1]), fontsize=9,\n",
    "                       ha='center', va='bottom')\n",
    "\n",
    "    # Cumulative variance\n",
    "    ax = plt.subplot(1, 4, 3)\n",
    "    x = range(1, 11)\n",
    "    safety_cumvar = np.cumsum(safety_results[layer]['variance_ratio'])\n",
    "    emotion_cumvar = np.cumsum(emotion_results[layer]['variance_ratio'])\n",
    "    ax.plot(x, safety_cumvar, 'o-', color='blue', label='Safety', linewidth=2)\n",
    "    ax.plot(x, emotion_cumvar, 's-', color='orange', label='Emotion', linewidth=2)\n",
    "    ax.axhline(y=0.9, color='red', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "    ax.set_xlabel('Number of Components')\n",
    "    ax.set_ylabel('Cumulative Variance Explained')\n",
    "    ax.set_title('Dimensional Requirements')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # PC1 distribution analysis for safety\n",
    "    ax = plt.subplot(1, 4, 4)\n",
    "    pc1_scores = safety_results[layer]['projections'][:, 0]\n",
    "    safe_scores = [pc1_scores[i] for i, l in enumerate(safety_labels) if l == 'safe']\n",
    "    unsafe_scores = [pc1_scores[i] for i, l in enumerate(safety_labels) if l == 'unsafe']\n",
    "\n",
    "    bins = np.linspace(min(pc1_scores), max(pc1_scores), 30)\n",
    "    ax.hist(safe_scores, bins=bins, alpha=0.5, label='Safe', color='green', density=True)\n",
    "    ax.hist(unsafe_scores, bins=bins, alpha=0.5, label='Unsafe', color='red', density=True)\n",
    "    ax.set_xlabel('PC1 Score')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title('PC1: The Safety Dimension')\n",
    "    ax.legend()\n",
    "    ax.axvline(x=0, color='black', linestyle='--', alpha=0.3)\n",
    "\n",
    "    # Calculate separation\n",
    "    safe_mean = np.mean(safe_scores)\n",
    "    unsafe_mean = np.mean(unsafe_scores)\n",
    "    separation = abs(safe_mean - unsafe_mean) / (np.std(safe_scores) + np.std(unsafe_scores))\n",
    "    ax.text(0.02, 0.95, f'Separation: {separation:.2f}σ',\n",
    "           transform=ax.transAxes, fontsize=10,\n",
    "           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "    plt.suptitle(f'Layer {layer}: Unsupervised Discovery of Cognitive Dimensions',\n",
    "                fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/visualizations/pca_discoveries_layer_{layer}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize PCA results\n",
    "# Note: Available layers are stored in the dictionaries. Check with:\n",
    "# print(f\"Available layers: {list(safety_pca_results.keys())}\")\n",
    "#\n",
    "# EXPERIMENT: Try different layers to see how PCA patterns change across depth!\n",
    "# - Early layers: More syntax/surface features\n",
    "# - Late layers: More semantic/abstract concepts\n",
    "#\n",
    "# Option 1: Use None to auto-select the best layer\n",
    "# Option 2: Choose a specific layer from the available ones\n",
    "layer_to_visualize = list(safety_pca_results.keys())[-1]  # Use the last (deepest) layer\n",
    "visualize_pca_discoveries(safety_pca_results, emotion_pca_results, layer=layer_to_visualize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2576567f",
   "metadata": {
    "id": "2576567f"
   },
   "source": [
    "## Section 3: Supervised Learning - Targeted Neural Engineering\n",
    "\n",
    "In Section 2, we used PCA to discover natural patterns in neural representations without any labels. While powerful, PCA doesn't know which patterns are relevant for our specific task (e.g., safety detection).\n",
    "\n",
    "Now we shift to *supervised learning*, where we use labeled examples to engineer detectors optimized for specific concepts. This section explores two approaches of increasing sophistication:\n",
    "1. **Mean Difference** (Simple Supervised): A baseline that subtracts class means\n",
    "2. **Logistic Regression** (Optimized Supervised): Finds the optimal linear separator\n",
    "\n",
    "Let's start with the simplest supervised approach to build intuition.\n",
    "\n",
    "### Mean Difference Method: A Simple Baseline\n",
    "\n",
    "**Key Idea:** If we have labeled examples of \"safe\" and \"unsafe\" text, the simplest\n",
    "way to find a separating direction is:\n",
    "1. Compute the average (mean) hidden state for all safe examples\n",
    "2. Compute the average (mean) hidden state for all unsafe examples  \n",
    "3. Subtract them: `direction = mean_safe - mean_unsafe`\n",
    "\n",
    "This gives us a vector pointing from \"unsafe\" toward \"safe\" in the representation space.\n",
    "\n",
    "**Limitation:** This method only uses the class means and ignores the variance and\n",
    "distribution of the data. Logistic regression (which you'll implement in Q6) is more\n",
    "sophisticated because it finds the *optimal* linear separator through optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b4ecac",
   "metadata": {
    "id": "20b4ecac"
   },
   "outputs": [],
   "source": [
    "def compute_mean_difference(H_pos: np.ndarray, H_neg: np.ndarray, normalize: bool = True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the direction that separates two classes using mean difference.\n",
    "\n",
    "    This is the simplest supervised method: just subtract the class means.\n",
    "    It's like finding the neural signature that distinguishes between\n",
    "    two mental states (e.g., safe vs unsafe).\n",
    "\n",
    "    Args:\n",
    "        H_pos: Hidden states for positive class (e.g., safe examples) [n_samples, hidden_dim]\n",
    "        H_neg: Hidden states for negative class (e.g., unsafe examples) [n_samples, hidden_dim]\n",
    "        normalize: Whether to normalize the direction to unit length\n",
    "\n",
    "    Returns:\n",
    "        direction: Vector pointing from negative to positive class [hidden_dim]\n",
    "    \"\"\"\n",
    "    mean_pos = H_pos.mean(axis=0)  # Average over all positive examples\n",
    "    mean_neg = H_neg.mean(axis=0)  # Average over all negative examples\n",
    "\n",
    "    direction = mean_pos - mean_neg  # Direction from negative to positive\n",
    "\n",
    "    if normalize:\n",
    "        direction = direction / (np.linalg.norm(direction) + 1e-8)  # Normalize to unit length\n",
    "\n",
    "    return direction\n",
    "\n",
    "def project_onto_direction(H: np.ndarray, direction: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Project hidden states onto a direction vector.\n",
    "\n",
    "    This gives us a score for each example: how much it aligns with the direction.\n",
    "    Higher scores mean the example is more similar to the positive class.\n",
    "\n",
    "    Args:\n",
    "        H: Hidden states [n_samples, hidden_dim]\n",
    "        direction: Direction vector [hidden_dim]\n",
    "\n",
    "    Returns:\n",
    "        scores: Projection scores [n_samples]\n",
    "    \"\"\"\n",
    "    direction = direction / (np.linalg.norm(direction) + 1e-8)  # Ensure normalized\n",
    "    return H @ direction  # Matrix multiplication gives dot product for each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea82330e",
   "metadata": {
    "id": "ea82330e"
   },
   "source": [
    "## **Question 5:** Supervised Safety Detection (15 points)\n",
    "\n",
    "### From Simple to Optimized: Logistic Regression\n",
    "\n",
    "Now you'll implement **logistic regression**, which goes beyond simple averaging to find the *optimized* linear separator between classes.\n",
    "\n",
    "**What you'll implement/analyze:**\n",
    "1. **Data preparation**: Split labeled data into train/test sets\n",
    "2. **Model training**: Train a logistic regression classifier\n",
    "3. **Evaluation**: Compute accuracy, AUC, and other metrics\n",
    "4. **Layer analysis**: Compare performance across different layers\n",
    "5. **Method comparison**: See how much better optimization is vs. simple mean difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e93da6",
   "metadata": {
    "id": "35e93da6"
   },
   "outputs": [],
   "source": [
    "def train_safety_classifier(safety_texts, safety_labels, model, tokenizer, layer, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Train a supervised safety classifier using logistic regression.\n",
    "\n",
    "    This function demonstrates the core supervised learning pipeline:\n",
    "    extracting features, splitting data, training, and evaluation.\n",
    "\n",
    "    Args:\n",
    "        safety_texts: List[str] - Text examples (both safe and unsafe)\n",
    "        safety_labels: List[str] - Labels ('safe' or 'unsafe') corresponding to texts\n",
    "        model: The language model to extract hidden states from\n",
    "        tokenizer: The tokenizer for the model\n",
    "        layer: int - Which layer to extract hidden states from\n",
    "        test_size: float - Fraction of data to use for testing (default: 0.2)\n",
    "\n",
    "    Returns:\n",
    "        results: dict containing:\n",
    "            - 'classifier': Trained LogisticRegression model\n",
    "            - 'accuracy': float - Test set accuracy\n",
    "            - 'auc': float - Area under ROC curve\n",
    "            - 'direction': np.ndarray - Learned weight vector (normalized)\n",
    "            - 'X_test': Test features (for later visualization)\n",
    "            - 'y_test': Test labels (for later visualization)\n",
    "            - 'y_pred': Predictions on test set\n",
    "            - 'y_prob': Prediction probabilities on test set\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "    # ============================================================\n",
    "    # STEP 1: Extract hidden states (features)\n",
    "    # ============================================================\n",
    "    print(f\"Extracting hidden states from layer {layer}...\")\n",
    "\n",
    "    # TODO: Extract hidden states for all texts at the specified layer\n",
    "    # Hint: Use get_hidden_states() function with layers=[layer]\n",
    "    # Expected output: Dictionary with key=layer, value=numpy array of shape [n_samples, hidden_dim]\n",
    "\n",
    "    # YOUR CODE HERE (1-3 lines)\n",
    "    hidden_dict =  \n",
    "    X =    # Shape: [n_samples, hidden_dim]\n",
    "\n",
    "    print(f\"  Extracted features shape: {X.shape}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # STEP 2: Prepare labels\n",
    "    # ============================================================\n",
    "    # Convert string labels to binary: 'safe' -> 1, 'unsafe' -> 0\n",
    "\n",
    "    # TODO: Create binary labels array\n",
    "    # Hint: Use list comprehension or np.array with conditional\n",
    "    # Expected output: numpy array of shape [n_samples] with values 0 or 1\n",
    "\n",
    "    # YOUR CODE HERE (1-2 lines)\n",
    "    y =  \n",
    "\n",
    "    print(f\"  Labels shape: {y.shape}\")\n",
    "    print(f\"  Class distribution: {np.sum(y == 0)} unsafe, {np.sum(y == 1)} safe\")\n",
    "\n",
    "    # ============================================================\n",
    "    # STEP 3: Split into train and test sets\n",
    "    # ============================================================\n",
    "    # Use train_test_split to create training and testing sets\n",
    "\n",
    "    # TODO: Split the data into train/test sets\n",
    "    # Hint: Use train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "    # Expected output: X_train, X_test, y_train, y_test\n",
    "\n",
    "    # YOUR CODE HERE (1 line)\n",
    "    X_train, X_test, y_train, y_test =  \n",
    "\n",
    "    print(f\"  Train set: {X_train.shape[0]} samples\")\n",
    "    print(f\"  Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "    # ============================================================\n",
    "    # STEP 4: Train logistic regression classifier\n",
    "    # ============================================================\n",
    "    print(\"Training logistic regression classifier...\")\n",
    "\n",
    "    # TODO: Create and train a LogisticRegression classifier\n",
    "    # Hint: Set max_iter to e.g., 1000\n",
    "    # Then use .fit()\n",
    "    # Expected output: Trained classifier object\n",
    "\n",
    "    # YOUR CODE HERE (2 lines)\n",
    "     \n",
    "\n",
    "    # ============================================================\n",
    "    # STEP 5: Make predictions and evaluate\n",
    "    # ============================================================\n",
    "    print(\"Evaluating on test set...\")\n",
    "\n",
    "    # TODO: Generate predictions and probabilities\n",
    "    # Hint: Use classifier.predict(X_test) and classifier.predict_proba(X_test)\n",
    "    # Expected output: y_pred (binary predictions), y_prob (probabilities for class 1)\n",
    "\n",
    "    # YOUR CODE HERE (2 lines)\n",
    "    y_pred =  \n",
    "    y_prob =    # Probability of class 1 (safe)\n",
    "\n",
    "    # TODO: Compute accuracy and AUC\n",
    "    # Hint: Use accuracy_score(y_test, y_pred) and roc_auc_score(y_test, y_prob)\n",
    "    # Expected output: accuracy (float), auc (float)\n",
    "\n",
    "    # YOUR CODE HERE (2 lines)\n",
    "    accuracy =  \n",
    "    auc =  \n",
    "\n",
    "    print(f\"  Accuracy: {accuracy:.3f}\")\n",
    "    print(f\"  AUC: {auc:.3f}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # STEP 6: Extract learned direction vector\n",
    "    # ============================================================\n",
    "    # The logistic regression weights represent the \"safety direction\"\n",
    "    # in the hidden state space\n",
    "\n",
    "    # TODO: Extract and normalize the weight vector\n",
    "    # Hint: classifier.coef_ gives the weights, use .flatten() to get 1D array\n",
    "    # Then normalize: direction / np.linalg.norm(direction)\n",
    "    # Expected output: direction (numpy array of shape [hidden_dim])\n",
    "\n",
    "    # YOUR CODE HERE (2-3 lines)\n",
    "    direction =  \n",
    "    direction =    # Normalize to unit length\n",
    "\n",
    "    # ============================================================\n",
    "    # VALIDATION CHECKS\n",
    "    # ============================================================\n",
    "    assert X_train.shape[0] + X_test.shape[0] == len(safety_texts), \"Data split error\"\n",
    "    assert y_pred.shape[0] == y_test.shape[0], \"Prediction shape mismatch\"\n",
    "    assert 0 <= accuracy <= 1, \"Accuracy out of range\"\n",
    "    assert 0 <= auc <= 1, \"AUC out of range\"\n",
    "    assert direction.shape[0] == X.shape[1], \"Direction dimension mismatch\"\n",
    "    assert abs(np.linalg.norm(direction) - 1.0) < 0.01, \"Direction not normalized\"\n",
    "\n",
    "    # Package results\n",
    "    results = {\n",
    "        'classifier': classifier,\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc,\n",
    "        'direction': direction,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'y_pred': y_pred,\n",
    "        'y_prob': y_prob\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b868a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98b868a6",
    "lines_to_next_cell": 2,
    "outputId": "deae0efe-5a27-44ef-d4c8-f80f2554a11a"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TEST YOUR IMPLEMENTATION\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"QUESTION 6: Testing Supervised Safety Classifier\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Recalculate layer config for current model to ensure compatibility\n",
    "LAYER_CONFIG = get_layer_ranges(model, print_config=False)\n",
    "\n",
    "# Select a layer to test (use a late layer where safety concepts emerge)\n",
    "test_layer = LAYER_CONFIG['safety_layers'][-1]\n",
    "print(f\"\\nTesting on layer {test_layer}...\")\n",
    "\n",
    "# Train the classifier\n",
    "q6_results = train_safety_classifier(\n",
    "    safety_texts=safety_texts,\n",
    "    safety_labels=safety_labels,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    layer=test_layer,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Training complete!\")\n",
    "print(f\"  Final accuracy: {q6_results['accuracy']:.3f}\")\n",
    "print(f\"  Final AUC: {q6_results['auc']:.3f}\")\n",
    "print(f\"  Direction vector shape: {q6_results['direction'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0d148",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3fa0d148",
    "lines_to_next_cell": 2,
    "outputId": "e4240f4b-af88-40fd-9384-02caffb10edb"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LAYER ANALYSIS (OPEN-ENDED EXPLORATION)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LAYER ANALYSIS: Comparing Performance Across Layers\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# TODO: Analyze how classification performance varies across layers\n",
    "# Try training classifiers on different layers and compare results\n",
    "# Suggested layers to try: early, middle, and late layers\n",
    "\n",
    "# YOUR CODE HERE - Implement layer comparison\n",
    "# Hint: Loop through different layers, call train_safety_classifier for each,\n",
    "# and store the results. Then visualize accuracy/AUC across layers.\n",
    "\n",
    "layer_comparison_results = {}\n",
    "\n",
    "# Ensure layer config is up to date for current model\n",
    "LAYER_CONFIG = get_layer_ranges(model, print_config=False)\n",
    "\n",
    "# Example structure (you can modify):\n",
    "layers_to_test = LAYER_CONFIG['exploration']  # or choose specific layers\n",
    "print(f\"\\nTesting layers: {layers_to_test}\")\n",
    "\n",
    "for layer in layers_to_test:\n",
    "    print(f\"\\n--- Layer {layer} ---\")\n",
    "    results = train_safety_classifier(\n",
    "        safety_texts=safety_texts,\n",
    "        safety_labels=safety_labels,\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        layer=layer,\n",
    "        test_size=0.2\n",
    "    )\n",
    "    layer_comparison_results[layer] = results\n",
    "\n",
    "# Visualize results\n",
    "layers = list(layer_comparison_results.keys())\n",
    "accuracies = [layer_comparison_results[l]['accuracy'] for l in layers]\n",
    "aucs = [layer_comparison_results[l]['auc'] for l in layers]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Accuracy across layers\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(layers, accuracies, 'o-', linewidth=2, markersize=8, color='steelblue')\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random baseline')\n",
    "plt.xlabel('Layer Index', fontsize=12)\n",
    "plt.ylabel('Test Accuracy', fontsize=12)\n",
    "plt.title('Safety Classification Accuracy by Layer', fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# Plot 2: AUC across layers\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(layers, aucs, 'o-', linewidth=2, markersize=8, color='darkorange')\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random baseline')\n",
    "plt.xlabel('Layer Index', fontsize=12)\n",
    "plt.ylabel('AUC Score', fontsize=12)\n",
    "plt.title('Safety Classification AUC by Layer', fontsize=13, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/student_analysis/q6_layer_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find best layer\n",
    "best_layer_acc = max(layer_comparison_results.keys(), key=lambda l: layer_comparison_results[l]['accuracy'])\n",
    "best_layer_auc = max(layer_comparison_results.keys(), key=lambda l: layer_comparison_results[l]['auc'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LAYER ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Best layer by accuracy: {best_layer_acc} (Acc={layer_comparison_results[best_layer_acc]['accuracy']:.3f})\")\n",
    "print(f\"Best layer by AUC: {best_layer_auc} (AUC={layer_comparison_results[best_layer_auc]['auc']:.3f})\")\n",
    "print(f\"\\nLayer range tested: {min(layers)} to {max(layers)}\")\n",
    "print(f\"Accuracy range: {min(accuracies):.3f} to {max(accuracies):.3f}\")\n",
    "print(f\"AUC range: {min(aucs):.3f} to {max(aucs):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0TaqtO6lYq3B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "id": "0TaqtO6lYq3B",
    "outputId": "bf5f5ef3-0b75-499e-a2ce-d888b3c4fd31"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SUPERVISED VS UNSUPERVISED COMPARISON\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARING SUPERVISED VS UNSUPERVISED APPROACHES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use the best performing layer from your analysis\n",
    "best_layer = best_layer_auc\n",
    "supervised_direction = layer_comparison_results[best_layer]['direction']\n",
    "X_test = layer_comparison_results[best_layer]['X_test']\n",
    "y_test = layer_comparison_results[best_layer]['y_test']\n",
    "y_prob = layer_comparison_results[best_layer]['y_prob']\n",
    "\n",
    "# Project test data onto supervised direction\n",
    "supervised_projections = X_test @ supervised_direction\n",
    "\n",
    "# Initialize PCA metrics\n",
    "pca_available = best_layer in safety_pca_results\n",
    "pca_auc = None\n",
    "pca_projections = None\n",
    "\n",
    "if pca_available:\n",
    "    # Get PCA direction and compute projections\n",
    "    pca_direction = safety_pca_results[best_layer]['components'][0]\n",
    "    pca_mean = safety_pca_results[best_layer]['mean']\n",
    "    pca_projections = (X_test - pca_mean) @ pca_direction\n",
    "\n",
    "    # Flip sign if needed so safe is positive\n",
    "    if np.mean(pca_projections[y_test == 1]) < np.mean(pca_projections[y_test == 0]):\n",
    "        pca_projections = -pca_projections\n",
    "\n",
    "    # Compute PCA AUC\n",
    "    from sklearn.metrics import roc_auc_score, roc_curve\n",
    "    pca_auc = roc_auc_score(y_test, pca_projections)\n",
    "\n",
    "    # Compute cosine similarity between directions\n",
    "    cosine_sim = np.dot(supervised_direction, pca_direction)\n",
    "\n",
    "    print(f\"\\nDirection Comparison (Layer {best_layer}):\")\n",
    "    print(f\"  Cosine similarity: {cosine_sim:.3f} ({abs(cosine_sim):.1%} alignment)\")\n",
    "\n",
    "    if abs(cosine_sim) > 0.7:\n",
    "        print(\"  → Highly aligned (both found similar patterns)\")\n",
    "    elif abs(cosine_sim) > 0.4:\n",
    "        print(\"  → Moderately aligned (some overlap)\")\n",
    "    else:\n",
    "        print(\"  → Weakly aligned (different patterns)\")\n",
    "\n",
    "    print(f\"\\nPerformance Comparison:\")\n",
    "    print(f\"  PCA (unsupervised):        AUC = {pca_auc:.3f}\")\n",
    "    print(f\"  Supervised (LogReg):       AUC = {layer_comparison_results[best_layer]['auc']:.3f}\")\n",
    "    print(f\"  Improvement:               {(layer_comparison_results[best_layer]['auc'] - pca_auc):.3f} ({(layer_comparison_results[best_layer]['auc'] - pca_auc)/pca_auc*100:+.1f}%)\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Supervised distribution\n",
    "ax = axes[0, 0]\n",
    "safe_proj = supervised_projections[y_test == 1]\n",
    "unsafe_proj = supervised_projections[y_test == 0]\n",
    "bins = np.linspace(min(supervised_projections), max(supervised_projections), 30)\n",
    "ax.hist(unsafe_proj, bins=bins, alpha=0.6, label='Unsafe', color='red', density=True)\n",
    "ax.hist(safe_proj, bins=bins, alpha=0.6, label='Safe', color='green', density=True)\n",
    "ax.set_xlabel('Projection Score', fontsize=11)\n",
    "ax.set_ylabel('Density', fontsize=11)\n",
    "ax.set_title(f'Supervised Detection (AUC={layer_comparison_results[best_layer][\"auc\"]:.3f})', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: PCA distribution (if available)\n",
    "ax = axes[0, 1]\n",
    "if pca_available:\n",
    "    safe_proj_pca = pca_projections[y_test == 1]\n",
    "    unsafe_proj_pca = pca_projections[y_test == 0]\n",
    "    bins_pca = np.linspace(min(pca_projections), max(pca_projections), 30)\n",
    "    ax.hist(unsafe_proj_pca, bins=bins_pca, alpha=0.6, label='Unsafe', color='red', density=True)\n",
    "    ax.hist(safe_proj_pca, bins=bins_pca, alpha=0.6, label='Safe', color='green', density=True)\n",
    "    ax.set_xlabel('Projection Score', fontsize=11)\n",
    "    ax.set_ylabel('Density', fontsize=11)\n",
    "    ax.set_title(f'PCA Detection (AUC={pca_auc:.3f})', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'PCA results not available\\nfor this layer',\n",
    "            ha='center', va='center', fontsize=12, transform=ax.transAxes)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "# Plot 3: ROC Curves comparison\n",
    "ax = axes[1, 0]\n",
    "fpr_sup, tpr_sup, _ = roc_curve(y_test, y_prob)\n",
    "ax.plot(fpr_sup, tpr_sup, linewidth=2.5, color='darkorange',\n",
    "        label=f'Supervised (AUC={layer_comparison_results[best_layer][\"auc\"]:.3f})')\n",
    "\n",
    "if pca_available:\n",
    "    fpr_pca, tpr_pca, _ = roc_curve(y_test, pca_projections)\n",
    "    ax.plot(fpr_pca, tpr_pca, linewidth=2.5, color='steelblue',\n",
    "            label=f'PCA (AUC={pca_auc:.3f})')\n",
    "    ax.fill_between(fpr_pca, 0, tpr_pca, alpha=0.15, color='steelblue')\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.3, label='Random')\n",
    "ax.fill_between(fpr_sup, 0, tpr_sup, alpha=0.2, color='darkorange')\n",
    "ax.set_xlabel('False Positive Rate', fontsize=11)\n",
    "ax.set_ylabel('True Positive Rate', fontsize=11)\n",
    "ax.set_title('ROC Curve Comparison', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Performance summary\n",
    "ax = axes[1, 1]\n",
    "methods = ['Supervised']\n",
    "aucs = [layer_comparison_results[best_layer]['auc']]\n",
    "colors_bar = ['darkorange']\n",
    "\n",
    "if pca_available:\n",
    "    methods.insert(0, 'PCA')\n",
    "    aucs.insert(0, pca_auc)\n",
    "    colors_bar.insert(0, 'steelblue')\n",
    "\n",
    "bars = ax.barh(methods, aucs, color=colors_bar, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "ax.axvline(x=0.5, color='red', linestyle='--', alpha=0.5, linewidth=1.5, label='Random baseline')\n",
    "ax.set_xlabel('AUC Score', fontsize=11)\n",
    "ax.set_title(f'Performance Summary (Layer {best_layer})', fontsize=12, fontweight='bold')\n",
    "ax.set_xlim([0, 1])\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, auc_val) in enumerate(zip(bars, aucs)):\n",
    "    ax.text(auc_val + 0.02, i, f'{auc_val:.3f}', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/student_analysis/q6_supervised_vs_pca_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f9700e",
   "metadata": {
    "id": "63f9700e",
    "lines_to_next_cell": 2
   },
   "source": [
    "### Required Analysis for Question 5\n",
    "\n",
    "1. **Understanding Supervised Learning (2 points)** What is the key difference between the supervised approach (logistic regression) and\n",
    "   the unsupervised approach (PCA) for safety detection? Consider:\n",
    "   - What information each method uses\n",
    "   - What each method optimizes for\n",
    "   - When you would prefer one over the other\n",
    "\n",
    "\n",
    "2. **Layer Analysis Results (3 points)** Based on your layer comparison experiments:\n",
    "   - Which layer(s) achieved the best performance? (Report specific layer numbers and metrics)\n",
    "   - Does performance improve, decline, or show a non-monotonic pattern?\n",
    "   - What might explain this trend based on what you know about how neural networks process information hierarchically?\n",
    "\n",
    "\n",
    "3. **Supervised vs Unsupervised Comparison (3 points)**\n",
    "   - Compare the supervised direction with PCA's first principal component: What is the cosine similarity between them? Are they aligned or different? What does this tell you?\n",
    "   - Compare the AUC scores between supervised and unsupervised: Which approach performs better for safety detection? By how much? Given that supervised learning requires labeled data, is the performance gain worth the cost?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a366954",
   "metadata": {
    "id": "0a366954"
   },
   "source": [
    "## **Question 6**: Understanding the Data Efficiency Curve (15 points)\n",
    "\n",
    "In the previous question, you saw that supervised learning (Logistic Regression) significantly outperforms  unsupervised learning (PCA). But there's a catch: **supervised learning requires labeled data**.\n",
    "\n",
    "Getting high quality data can be costly. **More data = better performance**: But at what point do we hit diminishing returns?\n",
    "\n",
    "Let's investigate this by training logistic regression with varying amounts of labeled data and compare against PCA baseline (which needs no labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j7lpg0RzYffY",
   "metadata": {
    "id": "j7lpg0RzYffY"
   },
   "outputs": [],
   "source": [
    "def supervision_learning_curve(cb_data, model, tokenizer,\n",
    "                              n_samples=[5, 10, 20, 50],\n",
    "                              n_runs=5):\n",
    "    \"\"\"\n",
    "    Analyze how supervised learning performance improves with more labeled data.\n",
    "\n",
    "    Question: How many labeled examples do we need before supervised\n",
    "    learning outperforms unsupervised PCA? What's the point of\n",
    "    diminishing returns?\n",
    "\n",
    "    Strategy:\n",
    "    1. Use safety dataset for consistent train/test split\n",
    "    2. Train supervised detectors with varying amounts of training data\n",
    "    3. Compare against PCA baseline (trained on full training set)\n",
    "    4. Find the \"sweet spot\" for labeling effort\n",
    "\n",
    "    Args:\n",
    "        n_samples: List of sample sizes to test\n",
    "        n_runs: Number of runs per sample size for variance estimation\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    # Store results for each run\n",
    "    all_results = {n: {'supervised': [], 'pca': []} for n in n_samples}\n",
    "\n",
    "    layer = list(safety_hidden.keys())[-1]\n",
    "\n",
    "    # Split safety dataset into train/test (80/20)\n",
    "    all_H = safety_hidden[layer]\n",
    "    all_labels = np.array([1 if l == 'safe' else 0 for l in safety_labels])\n",
    "\n",
    "    # Use a fixed random state for reproducible train/test split\n",
    "    X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "        all_H, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",
    "    )\n",
    "\n",
    "    # Get PCA baseline (trained on full training set, evaluated on test set)\n",
    "    components, mean, var_ratio = pca_from_scratch(X_train_full, n_components=1)\n",
    "    pca_proj = project_onto_components(X_test, components, mean)[:, 0]\n",
    "    if np.mean(pca_proj[y_test == 1]) < np.mean(pca_proj[y_test == 0]):\n",
    "        pca_proj = -pca_proj\n",
    "\n",
    "    pca_auc = roc_auc_score(y_test, pca_proj)\n",
    "\n",
    "    # Run multiple trials for each sample size\n",
    "    for n in n_samples:\n",
    "        if n > len(X_train_full):\n",
    "            continue\n",
    "\n",
    "        # Need at least 2 samples per class for stratified sampling\n",
    "        if n < 4:\n",
    "            print(f\"Skipping n={n}: need at least 4 samples for balanced sampling\")\n",
    "            continue\n",
    "\n",
    "        for run in range(n_runs):\n",
    "            # Stratified random sample from training set (ensures both classes present)\n",
    "            # Sample n//2 from each class\n",
    "            n_per_class = n // 2\n",
    "\n",
    "            safe_indices = np.where(y_train_full == 1)[0]\n",
    "            unsafe_indices = np.where(y_train_full == 0)[0]\n",
    "\n",
    "            # Randomly sample from each class\n",
    "            selected_safe = np.random.choice(safe_indices, n_per_class, replace=False)\n",
    "            selected_unsafe = np.random.choice(unsafe_indices, n_per_class, replace=False)\n",
    "\n",
    "            indices = np.concatenate([selected_safe, selected_unsafe])\n",
    "            np.random.shuffle(indices)  # Shuffle to mix classes\n",
    "\n",
    "            X_train_subset = X_train_full[indices]\n",
    "            y_train_subset = y_train_full[indices]\n",
    "\n",
    "            # Train logistic regression on subset\n",
    "            clf = LogisticRegression(max_iter=1000, random_state=None)  # Allow randomness across runs\n",
    "            clf.fit(X_train_subset, y_train_subset)\n",
    "\n",
    "            # Evaluate on test set\n",
    "            y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "            supervised_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "            all_results[n]['supervised'].append(supervised_auc)\n",
    "            all_results[n]['pca'].append(pca_auc)\n",
    "\n",
    "    # Compute statistics\n",
    "    results = []\n",
    "    for n in n_samples:\n",
    "        if n in all_results and all_results[n]['supervised']:\n",
    "            sup_mean = np.mean(all_results[n]['supervised'])\n",
    "            sup_std = np.std(all_results[n]['supervised'])\n",
    "            results.append({\n",
    "                'n_samples': n,\n",
    "                'supervised_auc': sup_mean,\n",
    "                'supervised_std': sup_std,\n",
    "                'pca_auc': pca_auc,\n",
    "                'improvement': (sup_mean - pca_auc) / pca_auc * 100,\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179631e3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "179631e3",
    "lines_to_next_cell": 2,
    "outputId": "0bc7ee3e-b773-4f20-ce5d-13820c84905e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TODO: Question 6 - Data Efficiency Experiment\n",
    "# ============================================================\n",
    "\n",
    "# Step 1: Define sample sizes to test\n",
    "# Test how performance changes with different amounts of labeled data\n",
    "# YOUR CODE HERE: Choose sample sizes to test\n",
    "# Hint: Try a range like [10, 20, 50, 100, 200, 500]\n",
    "sample_sizes_to_test = [10, 20, 50, 100, 200]  # Modify if needed\n",
    "\n",
    "# Step 2: Run the analysis\n",
    "# The supervision_learning_curve function is already implemented for you\n",
    "# It will train classifiers with different amounts of data and plot results\n",
    "\n",
    "# YOUR CODE HERE: Call the function with your sample sizes\n",
    "# Hint: learning_curve_results = supervision_learning_curve(\n",
    "#           cb_data=cb_data,\n",
    "#           model=model,\n",
    "#           tokenizer=tokenizer,\n",
    "#           n_samples=sample_sizes_to_test,\n",
    "#           n_runs=5  # Average over 5 runs for stability\n",
    "#       )\n",
    "\n",
    "learning_curve_results = supervision_learning_curve(cb_data, model, tokenizer, sample_sizes_to_test, 5)\n",
    "\n",
    "# The function will automatically generate a learning curve plot below\n",
    "# Examine the plot to answer the analysis questions\n",
    "\n",
    "# Visualize learning curve\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Extract data\n",
    "n_samples = [r['n_samples'] for r in learning_curve_results]\n",
    "supervised_aucs = [r['supervised_auc'] for r in learning_curve_results]\n",
    "supervised_stds = [r['supervised_std'] for r in learning_curve_results]\n",
    "pca_aucs = [r['pca_auc'] for r in learning_curve_results]\n",
    "\n",
    "# Plot: Learning curves with shaded uncertainty\n",
    "ax.plot(n_samples, supervised_aucs, 'o-', label='Supervised (LogReg)',\n",
    "        linewidth=2.5, markersize=10, color='darkorange')\n",
    "ax.fill_between(n_samples,\n",
    "                np.array(supervised_aucs) - np.array(supervised_stds),\n",
    "                np.array(supervised_aucs) + np.array(supervised_stds),\n",
    "                alpha=0.3, label='±1 std', color='darkorange')\n",
    "ax.axhline(y=pca_aucs[0], color='steelblue', linestyle='--',\n",
    "           linewidth=2.5, label=f'PCA Baseline (AUC={pca_aucs[0]:.3f})')\n",
    "ax.set_xlabel('Number of Training Samples', fontsize=12)\n",
    "ax.set_ylabel('AUC Score', fontsize=12)\n",
    "ax.set_title('Data Efficiency: How Performance Scales with Labeled Data', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(n_samples)\n",
    "ax.set_xticklabels([str(n) for n in n_samples])\n",
    "ax.set_ylim([0.5, 1.0])  # Set reasonable y-axis limits\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/student_analysis/q7_supervision_learning_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ca673",
   "metadata": {
    "id": "004ca673",
    "lines_to_next_cell": 2
   },
   "source": [
    "### Required Analysis for Question 6\n",
    "\n",
    "Based on your learning curve results, answer the following:\n",
    "\n",
    "**1. Crossover Analysis (2 points)**\n",
    "- At what sample size does supervised learning reliably outperform PCA?\n",
    "- What factors might influence this threshold? (Consider: data quality, task difficulty, feature dimensionality, class balance)\n",
    "\n",
    "**2. Learning Curve Shape (2 points)**\n",
    "- Describe the shape of the learning curve (linear, logarithmic, plateau?)\n",
    "- Where do you observe diminishing returns? (Identify the \"knee\" in the curve)\n",
    "- What does this suggest about data efficiency for this task?\n",
    "\n",
    "**3. Critical Thinking on Problem Setup (2 points)**\n",
    "\n",
    "Imagine you're a data scientist at a company deciding whether to purchase additional labeled data from a vendor or hire annotators. You want to use learning curves like the one above to make this decision.\n",
    "\n",
    "**Your task:**\n",
    "- What is unrealistic or problematic about using our current experimental setup to make real-world data acquisition decisions?\n",
    "- Why might this approach fail or be misleading in practice?\n",
    "- What would need to change to make data valuation more practical and reliable?\n",
    "\n",
    "**Consider:**\n",
    "- The timing of when you need to make the decision vs. when you can evaluate\n",
    "- What happens if your modeling approach changes later\n",
    "- What information you have access to at decision time vs. evaluation time\n",
    "\n",
    "**Hint:** Think about the difference between evaluating something you already have versus deciding whether to acquire something you don't have yet. Papers like [LAVA: Data Valuation without Pre-Specified Learning Algorithms](https://arxiv.org/abs/2305.00054) tackle related challenges in data valuation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b25e4be",
   "metadata": {
    "id": "1b25e4be",
    "lines_to_next_cell": 2
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "This neural archaeology project has taken you on a comprehensive journey through the internal representations of language models, revealing fundamental insights about how these systems organize and process information.\n",
    "- **Layer-wise Information Processing** This hierarchical processing mirrors findings in neuroscience about cortical processing hierarchies, suggesting deep parallels between biological and artificial neural systems.\n",
    "\n",
    "- **Concept Geometry and Dimensionality** The natural separability of important concepts without explicit training suggests that language models develop structured internal representations as an emergent property of next-token prediction.\n",
    "\n",
    "- **Supervised vs. Unsupervised Learning Trade-offs** Our comparative analysis demonstrated critical insights about representation learning.\n",
    "\n",
    "**Future Research Directions:** The path forward leads toward mechanistic interpretability, moving beyond correlations to causal understanding of actual circuits rather than just directional patterns. Robust alignment research must handle distribution shifts, resist adversarial attacks, and maintain capabilities while ensuring safety. Scalable oversight systems need to automate safety evaluation, learn efficiently from human feedback, and build self-improving safety mechanisms. Compositional control represents perhaps the most ambitious frontier: handling multiple objectives simultaneously, learning to compose interventions dynamically, and building truly modular safety systems. This journey marks not an end but a beginning, with the tools and insights gained serving as foundations for deeper exploration into the profound mysteries of artificial intelligence safety."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795467c-796f-412b-82c4-e710f3873bd7",
   "metadata": {
    "id": "9795467c-796f-412b-82c4-e710f3873bd7",
    "lines_to_next_cell": 2
   },
   "source": [
    "---\n",
    "\n",
    "**END OF ASSIGNMENT**\n",
    "\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "**Course Project**: This work was developed as an AI portfolio project for **ECE4424/CS4824 Machine Learning: Learn by Building** taught by Dr. Ming Jin at Virginia Tech (https://jinming99.github.io/learn-ml-by-building/)\n",
    "\n",
    "**Teaching Assistants**: Special thanks to Kamal Sherawat (kamals@vt.edu) and Darshan Nere (darshannere@vt.edu) for their invaluable assistance in fine-tuning this notebook and generating promising results.\n",
    "\n",
    "**Key References:**\n",
    "\n",
    "- **Representation Engineering** - [Zou et al., 2023](https://arxiv.org/abs/2310.01405)\n",
    "- **Circuit Breaker** - [Zou et al., 2024](https://www.circuit-breaker.ai/)\n",
    "- **Backtracking for Safety** - [Zhang et al., 2024](https://arxiv.org/abs/2409.14586), [Sel et al., 2025](https://arxiv.org/abs/2503.08919)\n",
    "\n",
    "**Datasets:**\n",
    "- [Representation Engineering Github](https://github.com/andyzoujm/representation-engineering): emotion dataset\n",
    "- [Circuit Breaker Github](https://github.com/GraySwanAI/circuit-breakers/tree/main/data): safety dataset\n",
    "\n",
    "**AI-Assisted Development**: Large language models were utilized as collaborative tools in developing this educational material, assisting with code generation, documentation, and exploring different implementation strategies. All outputs were thoroughly reviewed, tested, and refined to ensure accuracy and alignment with course objectives.\n",
    "\n",
    "**Ethical Note**: These techniques carry significant responsibility. Users should apply these methods ethically and exclusively for beneficial purposes, always considering the potential impacts of AI system modifications on end users and society."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python (ml_lectures_env)",
   "language": "python",
   "name": "ml_lectures_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0af57d40c6cd46dd8d093bb5212d00cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5fcdc762c0444c7da401927838d2ea78",
       "IPY_MODEL_e8f6b75cbd1e49d2a0ef18e0fa40933a",
       "IPY_MODEL_c0950e254a824dab863ce525720a433a"
      ],
      "layout": "IPY_MODEL_fd4bf01df914490b84b7a2fa7389d4f4"
     }
    },
    "0e998ae00b574c08bb95ee4ca54b7b18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f6224b6d99c41eabcec948735274052": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d6586b7682e4c1da166373c2c638a74",
       "IPY_MODEL_3e6eb46ac8ce4afb889826c30221f9a6",
       "IPY_MODEL_79b49afd52214e8abacfd77499b6370b"
      ],
      "layout": "IPY_MODEL_c747b1e0398840d2aec8bc86432c9c69"
     }
    },
    "14888ecd16404cc7b3a27f5ba19d5c77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14f85c8d3a15411283b21a30ce52eee1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1880536b5117470787e281a93311c6e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "18eb41620ac94e6b86e14e39738a3eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d814a1478330460683f79de97cd35fb2",
      "placeholder": "​",
      "style": "IPY_MODEL_f94c6e535de64358bf281a7c93577c4a",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "1b9b3055b20240c49adac22157dd0d13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_70babe96b7b1429fa17f4c40cad9c152",
       "IPY_MODEL_1be4463d2cd84c64b98c61f30f7862e4",
       "IPY_MODEL_81dcf013dedc4f0ba7b32dd117ebae40"
      ],
      "layout": "IPY_MODEL_58aa31d9da994c15975f460d1e408f0d"
     }
    },
    "1be4463d2cd84c64b98c61f30f7862e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14888ecd16404cc7b3a27f5ba19d5c77",
      "max": 3422777952,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f0d5f4aaffbf4c3481be47f8c5a6ee41",
      "value": 3422777952
     }
    },
    "1d85581233bf41cf9d1800344e79e38c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b944feb9040343cea1095a8de5a2812f",
      "max": 156,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a9c6537f0e54506a704dd583a9c97a4",
      "value": 156
     }
    },
    "2ec0ec2709974a4e8b9f39255d5617e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dea9624623804c18bce55ca0fdd723de",
      "placeholder": "​",
      "style": "IPY_MODEL_77ec276a0577468094eccb16f0dde63d",
      "value": " 156/156 [00:00&lt;00:00, 17.6kB/s]"
     }
    },
    "308364e795c843e2abd0f219279e0bbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c2fdce86da6435ca363e66e46db660c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e20ec616ad54ac3957572b60a6dec01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e72423f831fd46f3bf06c0ab7ba76797",
       "IPY_MODEL_9921643026b34e85a5147184605e45d3",
       "IPY_MODEL_65446d8272194d7e99923ec420d03306"
      ],
      "layout": "IPY_MODEL_6aa26741142141a29bf183e176a6620d"
     }
    },
    "3e6eb46ac8ce4afb889826c30221f9a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea2bb067b26d40f29e56209e2315a3ba",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8d114858bbf649a58c3bf48ee72f91b5",
      "value": 1
     }
    },
    "41867e86de9a4fc2bf8388ee9f09c484": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c12c9f985b0a49078dd9fc3a6cde1a88",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14f85c8d3a15411283b21a30ce52eee1",
      "value": 1
     }
    },
    "46ed85e98bb54834bce1cb957f1bf386": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4926d614003c489dbe0553ae0763871b",
      "placeholder": "​",
      "style": "IPY_MODEL_308364e795c843e2abd0f219279e0bbd",
      "value": "generation_config.json: 100%"
     }
    },
    "4926d614003c489dbe0553ae0763871b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a9c6537f0e54506a704dd583a9c97a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4aeb57348db34ba19d4a1510f248508c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "538f9d622be747f09aa6da58a2732acc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18eb41620ac94e6b86e14e39738a3eda",
       "IPY_MODEL_8d7f5b86b4e04942a9f6e47624c4ba49",
       "IPY_MODEL_aec17c3c77e648d29ea527fbe67a4a8a"
      ],
      "layout": "IPY_MODEL_7527ac40d7bd436381a82c844beaf717"
     }
    },
    "5490c1d7addd421588888c6d6353b970": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "561cff1e257a42ff86052de8e9111bda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5863477165f14251976615a199a8e351": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58aa31d9da994c15975f460d1e408f0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cf6e14604ee4cbb90ea7f374c127208": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec757bf395c4436a9469a5c79bf61d23",
       "IPY_MODEL_cc72be3c90024888979e194f7d22f1bc",
       "IPY_MODEL_bae897e743a24edd9c6e8159f6961977"
      ],
      "layout": "IPY_MODEL_656cc4584d9e49699fa3fdd6c7767969"
     }
    },
    "5fcdc762c0444c7da401927838d2ea78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f3e62985b594194bf984c74f451d3c7",
      "placeholder": "​",
      "style": "IPY_MODEL_9e27b9466d3e4030bb85d955b6ea8f96",
      "value": "config.json: 100%"
     }
    },
    "636341bfc52d43f985f69e35f86f3190": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "644c316bde7d478e9dae9e49f73cb829": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65446d8272194d7e99923ec420d03306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed3eb6b6939645e4b30c661dacf00f2b",
      "placeholder": "​",
      "style": "IPY_MODEL_ef92d284cce1430e81ccf3e322c2cab3",
      "value": " 801k/? [00:00&lt;00:00, 1.20MB/s]"
     }
    },
    "656cc4584d9e49699fa3fdd6c7767969": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69867e7d2b6b46bbadbb2147c48cfcab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6aa26741142141a29bf183e176a6620d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b1635ab51884e188b524377a4825a0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6bf4f9d3822a45d696fb69f80420858a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a5c2e4a36c842c89a70d56e0dfbc209",
      "placeholder": "​",
      "style": "IPY_MODEL_561cff1e257a42ff86052de8e9111bda",
      "value": " 2.10M/? [00:00&lt;00:00, 10.9MB/s]"
     }
    },
    "70492af00c0e4df183c2b473d7b276c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70babe96b7b1429fa17f4c40cad9c152": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5863477165f14251976615a199a8e351",
      "placeholder": "​",
      "style": "IPY_MODEL_882ce2a9bf3c4d3b88c8e7c746b7c097",
      "value": "model.safetensors: 100%"
     }
    },
    "713d2df2162a41ed96e92304a4678606": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7527ac40d7bd436381a82c844beaf717": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77ec276a0577468094eccb16f0dde63d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79b49afd52214e8abacfd77499b6370b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d49643472146465a9db63534352ff2c6",
      "placeholder": "​",
      "style": "IPY_MODEL_f959e07b8837418e8f49adc4fa17ccf2",
      "value": " 466k/? [00:00&lt;00:00, 7.09MB/s]"
     }
    },
    "81dcf013dedc4f0ba7b32dd117ebae40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e84762ae5fa44d1686680aa6d91ea723",
      "placeholder": "​",
      "style": "IPY_MODEL_6b1635ab51884e188b524377a4825a0e",
      "value": " 3.42G/3.42G [02:20&lt;00:00, 31.2MB/s]"
     }
    },
    "81f76d9e08c140bda6a050335ad89971": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "882ce2a9bf3c4d3b88c8e7c746b7c097": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a9e3028ac794088959e473fd5fcf402": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d114858bbf649a58c3bf48ee72f91b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d6586b7682e4c1da166373c2c638a74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_636341bfc52d43f985f69e35f86f3190",
      "placeholder": "​",
      "style": "IPY_MODEL_ed54017801bf43a48bf857706cbcf5d4",
      "value": "merges.txt: "
     }
    },
    "8d7f5b86b4e04942a9f6e47624c4ba49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69867e7d2b6b46bbadbb2147c48cfcab",
      "max": 655,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5490c1d7addd421588888c6d6353b970",
      "value": 655
     }
    },
    "9921643026b34e85a5147184605e45d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6d461c946954f6ea569f5619325fdbd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_baa371ceb638480bbd1c25319c7cc5d9",
      "value": 1
     }
    },
    "992980546f8a4c2180167bc08246bbc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a5c2e4a36c842c89a70d56e0dfbc209": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e27b9466d3e4030bb85d955b6ea8f96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f3e62985b594194bf984c74f451d3c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a094c5b4e6474257b2d4be833d9069d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6d461c946954f6ea569f5619325fdbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "aa4b75d65c224b10a27abab3a9fdc73b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_46ed85e98bb54834bce1cb957f1bf386",
       "IPY_MODEL_1d85581233bf41cf9d1800344e79e38c",
       "IPY_MODEL_2ec0ec2709974a4e8b9f39255d5617e7"
      ],
      "layout": "IPY_MODEL_d85154d0cf464328a1eb72326e4f97d5"
     }
    },
    "ab985892d83d4bcabfb1b15dc6752b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d6bee1d9697041d7a88c084da11850e4",
       "IPY_MODEL_41867e86de9a4fc2bf8388ee9f09c484",
       "IPY_MODEL_6bf4f9d3822a45d696fb69f80420858a"
      ],
      "layout": "IPY_MODEL_0e998ae00b574c08bb95ee4ca54b7b18"
     }
    },
    "aec17c3c77e648d29ea527fbe67a4a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de050f3c08b84177aae0ca8419dc40a1",
      "placeholder": "​",
      "style": "IPY_MODEL_992980546f8a4c2180167bc08246bbc0",
      "value": " 655/655 [00:00&lt;00:00, 74.6kB/s]"
     }
    },
    "b03f265cdd7845e3a93b5515fd9b0498": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b944feb9040343cea1095a8de5a2812f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "baa371ceb638480bbd1c25319c7cc5d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bae897e743a24edd9c6e8159f6961977": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4aeb57348db34ba19d4a1510f248508c",
      "placeholder": "​",
      "style": "IPY_MODEL_c54118528ac04c05a0af635afc157de5",
      "value": " 3.59k/? [00:00&lt;00:00, 162kB/s]"
     }
    },
    "c0950e254a824dab863ce525720a433a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e790a2638af54662a602aa3faa836f2d",
      "placeholder": "​",
      "style": "IPY_MODEL_fff0ccbbd7874f2e8651303f7c53f602",
      "value": " 738/738 [00:00&lt;00:00, 88.5kB/s]"
     }
    },
    "c12c9f985b0a49078dd9fc3a6cde1a88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "c54118528ac04c05a0af635afc157de5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c747b1e0398840d2aec8bc86432c9c69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc72be3c90024888979e194f7d22f1bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1880536b5117470787e281a93311c6e6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_644c316bde7d478e9dae9e49f73cb829",
      "value": 1
     }
    },
    "d49643472146465a9db63534352ff2c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6bee1d9697041d7a88c084da11850e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b03f265cdd7845e3a93b5515fd9b0498",
      "placeholder": "​",
      "style": "IPY_MODEL_713d2df2162a41ed96e92304a4678606",
      "value": "tokenizer.json: "
     }
    },
    "d814a1478330460683f79de97cd35fb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d85154d0cf464328a1eb72326e4f97d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db67461ca6034592856480e02b479252": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de050f3c08b84177aae0ca8419dc40a1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dea9624623804c18bce55ca0fdd723de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e72423f831fd46f3bf06c0ab7ba76797": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c2fdce86da6435ca363e66e46db660c",
      "placeholder": "​",
      "style": "IPY_MODEL_db67461ca6034592856480e02b479252",
      "value": "vocab.json: "
     }
    },
    "e790a2638af54662a602aa3faa836f2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e84762ae5fa44d1686680aa6d91ea723": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8f6b75cbd1e49d2a0ef18e0fa40933a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70492af00c0e4df183c2b473d7b276c1",
      "max": 738,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a9e3028ac794088959e473fd5fcf402",
      "value": 738
     }
    },
    "ea2bb067b26d40f29e56209e2315a3ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ec757bf395c4436a9469a5c79bf61d23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a094c5b4e6474257b2d4be833d9069d2",
      "placeholder": "​",
      "style": "IPY_MODEL_81f76d9e08c140bda6a050335ad89971",
      "value": "tokenizer_config.json: "
     }
    },
    "ed3eb6b6939645e4b30c661dacf00f2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed54017801bf43a48bf857706cbcf5d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef92d284cce1430e81ccf3e322c2cab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0d5f4aaffbf4c3481be47f8c5a6ee41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f94c6e535de64358bf281a7c93577c4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f959e07b8837418e8f49adc4fa17ccf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd4bf01df914490b84b7a2fa7389d4f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fff0ccbbd7874f2e8651303f7c53f602": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
